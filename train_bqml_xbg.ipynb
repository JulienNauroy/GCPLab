{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aklJxkHBD5aR"
   },
   "source": [
    "# Predicting using BigQuery ML & XGBoost\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Machine Learning using BigQuery\n",
    "<li> Jupyter Magic for BigQuery in Cloud Datalab\n",
    "</ol>\n",
    "\n",
    "Please see [this notebook](1_explore.ipynb) for more context on this problem and how the features were chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BhUiclqCD5aT"
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "PROJECT = 'data-science-showroom'\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F10_KsX7D5aX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YrqwSv6vD5aZ",
    "outputId": "402ed11b-ab4a-4480-a1aa-f72741cd2cc1"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j782YaAzD5ae"
   },
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Here, we will be taking natality data and training on features to predict the birth weight.\n",
    "\n",
    "The CDC's Natality data has details on US births from 1969 to 2008 and is available in BigQuery as a public data set. More details: https://bigquery.cloud.google.com/table/publicdata:samples.natality?tab=details\n",
    "\n",
    "Lets start by looking at the data since 2000 with useful values > 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "odWaIcLdD5af",
    "outputId": "2654ad9b-a735-4cd3-c3d9-80ebed8ed6bf"
   },
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "WITH DATA AS\n",
    "(SELECT \n",
    "       MOD(JOBID,4) AS HASH_JOBID, VERSION, PERFORMANCE, PRECISION, MPLINK, NTNU, MPLINK_NTNU,\n",
    "       MBS, RUNEND, TIMESTEP, NBNODES, NBELEM1D, NBELEM2D,\n",
    "       NBELEM3D, CLUSTER, NBSERVERS, NBCORE, DATACHECK_TIME,\n",
    "       ELAPSEDTIME\n",
    "FROM\n",
    "  `challenge.training_data`)\n",
    "\n",
    "SELECT * FROM DATA WHERE HASH_JOBID >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-d7C8KcD5am"
   },
   "source": [
    "## Train Model\n",
    "\n",
    "With the relevant columns chosen to accomplish predictions, it is then possible to create (train) the model in BigQuery. First, a dataset will be needed store the model. (if this throws an error in Datalab, simply create the dataset from the BigQuery console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bWMZJQdKD5an"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bq --location=EU mk -d demo_youripn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9JZIQ9nD5ap"
   },
   "source": [
    "With the demo dataset ready, it is possible to create a linear regression model to train the model.\n",
    "\n",
    "This will take approximately **4 minutes** to run and will show **Done** when complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V-UJOX0tD5aq",
    "outputId": "63aa219c-a14f-4db5-a271-2e614759fe1a"
   },
   "outputs": [],
   "source": [
    "%%bigquery model\n",
    "CREATE or REPLACE MODEL demo_youripn.xgboost_model\n",
    "TRANSFORM( ML.STANDARD_SCALER(PRECISION) OVER() AS PRECISION,\n",
    "           ML.STANDARD_SCALER(RUNEND) OVER() AS RUNEND,\n",
    "           ML.STANDARD_SCALER(TIMESTEP) OVER() AS TIMESTEP,\n",
    "           ML.STANDARD_SCALER(NBNODES) OVER() AS NBNODES,\n",
    "           ML.STANDARD_SCALER(NBELEM1D) OVER() AS NBELEM1D,\n",
    "           ML.STANDARD_SCALER(NBELEM2D) OVER() AS NBELEM2D,\n",
    "           ML.STANDARD_SCALER(NBELEM3D) OVER() AS NBELEM3D,\n",
    "           ML.STANDARD_SCALER(NBSERVERS) OVER() AS NBSERVERS,\n",
    "           ML.STANDARD_SCALER(NBCORE) OVER() AS NBCORE,\n",
    "           ML.STANDARD_SCALER(DATACHECK_TIME) OVER() AS DATACHECK_TIME,\n",
    "           VERSION,\n",
    "           PERFORMANCE,\n",
    "           MPLINK,\n",
    "           NTNU,\n",
    "           MPLINK_NTNU,\n",
    "           MBS,\n",
    "           CLUSTER,\n",
    "           ML.FEATURE_CROSS(STRUCT(PERFORMANCE, MPLINK, NTNU, CLUSTER)) AS CROSS_F,\n",
    "           ELAPSEDTIME)\n",
    "OPTIONS(MODEL_TYPE='BOOSTED_TREE_REGRESSOR',\n",
    "        BOOSTER_TYPE = 'GBTREE',\n",
    "        L1_REG = 0.1,\n",
    "        L2_REG = 0.01,\n",
    "        NUM_PARALLEL_TREE = 1,\n",
    "        MAX_ITERATIONS = 30,\n",
    "        TREE_METHOD = 'HIST',\n",
    "        EARLY_STOP = FALSE,\n",
    "        SUBSAMPLE = 0.85,\n",
    "        INPUT_LABEL_COLS = ['ELAPSEDTIME'])\n",
    "AS \n",
    "SELECT \n",
    "       *\n",
    "FROM\n",
    "  `challenge.training_data`\n",
    "WHERE MOD(JOBID,4)<3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJYtGxWyD5at"
   },
   "source": [
    "## Training Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L92s-gtD5au"
   },
   "source": [
    "During the model training (and after the training), it is possible to see the model's training evaluation statistics.\n",
    "\n",
    "For each training run, a table named `<model_name>_eval` is created. This table has basic performance statistics for each iteration.\n",
    "\n",
    "While the new model is training, review the training statistics in the BigQuery UI to see the below model training: https://bigquery.cloud.google.com/\n",
    "\n",
    "Since these statistics are updated after each iteration of model training, you will see different values for each refresh while the model is training.\n",
    "\n",
    "The training details may also be viewed after the training completes from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZbV6aDcRD5au",
    "outputId": "9518b192-2f7f-4b69-e612-2e3068f9925c"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM ML.TRAINING_INFO(MODEL demo_youripn.xgboost_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CATWu60vD5ay"
   },
   "source": [
    "Some of these columns are obvious although what do the non-specific ML columns mean (specific to BQML)?\n",
    "\n",
    "**training_run** - Will be zero for a newly created model. If the model is re-trained using warm_start, this will increment for each re-training.\n",
    "\n",
    "**iteration** - Number of the associated `training_run`, starting with zero for the first iteration.\n",
    "\n",
    "**duration_ms** - Indicates how long the iteration took (in ms).\n",
    "\n",
    "Note: You can also see these stats by refreshing the BigQuery UI window, finding the `<model_name>` table, selecting on it, and then the Training Stats sub-header.\n",
    "\n",
    "Let's plot the training and evaluation loss to see if the model has an overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Add--LfeD5a2"
   },
   "source": [
    "As you can see, the training loss and evaluation loss are essentially identical. We do not seem to be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QPwMA_ZD5a3"
   },
   "source": [
    "## Model Evaluation with BQML using the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QBZxMb6D5a5"
   },
   "source": [
    "With a trained model, it is now possible to make a prediction on the values. The only difference from the second query above is the reference to the model. The data has been limited (`LIMIT 100`) to reduce amount of data returned.\n",
    "\n",
    "When the `ml.predict` function is leveraged, output prediction column name for the model is `predicted_<label_column_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "x-hedqSeD5a6",
    "outputId": "e9bbeb43-900c-420a-8520-2feeccf79239"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ml.EVALUATE(MODEL demo_youripn.xgboost_model,\n",
    "(SELECT \n",
    "    *\n",
    "FROM\n",
    "  `challenge.training_data`\n",
    "WHERE MOD(JOBID,4) =3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery data\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ml.PREDICT(MODEL demo_youripn.xgboost_model,\n",
    "(SELECT \n",
    "    *\n",
    "FROM\n",
    "  `challenge.competition`\n",
    "WHERE MOD(JOBID,4) =0))\n",
    "    LIMIT 1000"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "babyweight_bqml.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "environment": {
   "name": "tf2-cpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
