{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYqIW7eq0mch"
   },
   "source": [
    "# **PamCrash dataset analysis**\n",
    "\n",
    "Renault’s Engineering teams need to perform thousands of crash simulation each day for validating the safety of the next generations of vehicles. These simulations run on DIRE’s HPC Platform, which comprises about 100.000 CPU cores and a specialized server infrastructure. Each simulation takes multiple hours, sometimes days, on multiple servers used in parallel. A typical crash simulation takes about 8 hours on 180 CPU cores (5 servers). \n",
    "\n",
    "The annual cost of simulation is in the millions of euros, including infrastructure costs (servers) and license costs. It is thus crucial to optimize the way crash simulations are executed. \n",
    "\n",
    "To limit the cost, one possibility would be to slow down simulations when there’s not business impact. The scenario would be the following: if a simulation would complete outside of the engineering business hours, the simulation could be slowed down to complete right before the next work session (e.g. the day after or on Monday morning). \n",
    "\n",
    "Slowing down simulations saves money the same way driving slower saves gasoline for the same distance driven. Our usual cost metric is the number of core multiplied by the number of hours they are used, noted core.hours and the faster the simulation, the higher the number of core.hours spent for a given simulation, thus the higher the cost.\n",
    "\n",
    "Automatically slowing down simulations running outside business hours should have no impact on the business. One prerequisite to automatically slow down these simulations is to be able to accurately predict the time they would take depending on the number of allocated servers, in order to predict the optimal number of cores to allocate to a simulation to ensure the business do not wait for the result. A simulation returned too early leads to an unnecessary extra cost; a simulation arriving too late leads to a loss of productivity for the engineer or the team waiting for the result. \n",
    "\n",
    "The objective of this challenge is to build a reliable and robust predictor that can be used in an algorithm for deciding the number of cores to be allocated to a simulation. The construction of the decision algorithm based on this predictor is outside the scope of this study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYLruuUEaEMn"
   },
   "source": [
    "# Nouvelle section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6octVTou1x-B"
   },
   "source": [
    "### **Linking the notebook to the drive to access the dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code if running on GCP's Labs for Renault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "SELECT \n",
    "*\n",
    "FROM\n",
    "  `challenge.training_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code if running on Google Colaboratory instead, or your own Jupyter Notebook\n",
    "#import pandas as pd\n",
    "#train_df = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1nYfF1tsQtEo0YBAlu0iE5qohp7kAKe2c&export=download\", sep=\";\")\n",
    "#train_df = train_df.rename(columns={\"TZC FINAL\": \"TZC_FINAL\"}, errors=\"raise\")\n",
    "#train_df = train_df.rename(columns={\"MPLINK+NTNU\": \"MPLINK_NTNU\"}, errors=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zANJzWAv2GcF"
   },
   "source": [
    "### **Loading the libraries required for the analysis and plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyVsQEU4CI0v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFD22TwQ2xN4"
   },
   "source": [
    "### **Creating some usefull functions**\n",
    "\n",
    "- **filter**: filter the dataframe by column value.\n",
    "\n",
    "- **discretize**: transforms the values of a column from continuous to categorical. discretize( [10,11,15,19,21],[15,20]) returns [0,0,1,1,2] (0 for x<15, 1 for 15<=x<20, 2 for x>=20)\n",
    "\n",
    "- **plot_pie**: draws a pie of the distribution of values of a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0PUN7fCnUz"
   },
   "outputs": [],
   "source": [
    "def filter_aux(first, op, last):\n",
    "    ops = {'>': operator.gt,\n",
    "           '<': operator.lt,\n",
    "           '>=': operator.ge,\n",
    "           '<=': operator.le,\n",
    "           '==': operator.eq}\n",
    "    return ops[op](first, last)\n",
    "\n",
    "def filter(data, category, op, value):\n",
    "    m = filter_aux(data[category], op, value)\n",
    "    df = data[m]\n",
    "    return df\n",
    "\n",
    "def discretize(data, bins):\n",
    "    data = np.asarray(data)\n",
    "    data = np.digitize(data, bins)\n",
    "    return data\n",
    "\n",
    "def plot_pie(data, category, title, lb=None, ax1=None):\n",
    "  dic = {}\n",
    "  labels = list(set(data[category]))\n",
    "  if lb == None:\n",
    "    lb = labels\n",
    "  sizes = []\n",
    "  explode = np.zeros((len(labels)))\n",
    "  for value in labels:\n",
    "    nom = len(filter(data, category, \"==\", value))\n",
    "    dic[value] = (nom/ len(data[category])) * 100\n",
    "    sizes.append(dic[value])\n",
    "  explode[sizes.index(max(sizes))] = 0.1\n",
    "  explode = tuple(explode)\n",
    "  fig1, ax1 = plt.subplots()\n",
    "  wedges, autotexts =ax1.pie(sizes, explode=explode, textprops=dict(color=\"w\"))\n",
    "  ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "  ax1.legend(wedges, lb ,\n",
    "            title = title,\n",
    "            loc = \"center left\",\n",
    "            bbox_to_anchor = (1, 0, 0.5, 1))\n",
    "\n",
    "  plt.setp(autotexts, size=8, weight=\"bold\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1XOzMkIRpM2"
   },
   "source": [
    "### **What does our dataset look like?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME-Hi510f1gk"
   },
   "source": [
    "#### **Columns description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXAsJT_6gNvo"
   },
   "source": [
    "We load the dataset and use pandas.head() to visualize a sample of the data. The following is a brief explanation of each column:\n",
    "\n",
    "**JOBID**: The ID of each simulation (for information only).\n",
    "\n",
    "**PERFORMANCE**: Type of crash performance (front crash, lateral, pedestrian, etc).\n",
    "\n",
    "**PRECISION**: Numerical precision (simple or double). Impacts the performance of the simumation.\n",
    "\n",
    "**RUNEND**: The duration of the simulation, in milliseconds.\n",
    "\n",
    "**TIMESTEP**: A time step given by the user in ms. The maximum number of iterations is equal to RUNEND/TIMESTEP but the simulation can be stopped earlier.\n",
    "\n",
    "**DATACHECK_TIME**: Execution time (in seconds) of the pre-computing phase, allowing us to check that the parameters are valid.\n",
    "\n",
    "**NBNODES**: Total amount of nodes of the model. The 1D, 2D and 3D elements are composed of such nodes.\n",
    "\n",
    "**NBELEM2D**: Number of 2D elements in the model. Each element composed of several nodes.\n",
    "\n",
    "**ELAPSEDTIME**: Total time of the simulation, in seconds. This is the variable we're trying to predict.\n",
    "\n",
    "**TZC**: Output column. Average time required per node per iteration. This column is given for advanced usage only because predicting TZC may help predicting ELAPSEDTIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1603989864231,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "zIDIOIJl66IC",
    "outputId": "33429bef-e7dd-4cd1-8c91-de039c2812f7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1603989864235,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "NtNEEQYOkFwQ",
    "outputId": "239c6f5e-f7f0-4c4c-d9c9-2ffdeb4d52db"
   },
   "outputs": [],
   "source": [
    "# let's analyse the dataset structure (\"object\" means \"string\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bF5rIQxYgdYJ"
   },
   "source": [
    "#### **A bit of statistical analysis on the data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU-uQoDfeluF"
   },
   "source": [
    "**Removing some useless columns**\n",
    "\n",
    "The ID of the simulation, the day and the hour the simulation is started shouldn't have any impact on its run time so we remove it. \"TZC FINAL\" is an ouput column and we don't iterate on it in this baseline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhZZzuleCKlp"
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"JOBID\", \"DAY\", \"HOUR\", \"TZC_FINAL\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PADQPsTdhc-h"
   },
   "source": [
    "**Understanding the dataset**\n",
    "\n",
    "We compute some statistical analysis functions on each column such as the mean, standard deviation, frequency, etc.\n",
    "\n",
    "If a statistic isn't compatible with the column type, a \"NaN\" value will be dispalyed (such as mean or std for a categorical variable).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1603989865734,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "4b4dtzyXbpHR",
    "outputId": "f9a3e6f5-fc3f-46a5-9516-8296bbeb88d4"
   },
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-1HYj7ujwXE"
   },
   "source": [
    "**Keeping only the HPC3 Cluster**\n",
    "\n",
    "We'll focus only on HPC3 cluster in the training since this is the cluster on which the number of servers vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grD5O6cRlRP_"
   },
   "outputs": [],
   "source": [
    "HPC3 = df[df[\"CLUSTER\"] == \"HPC3\"].drop([\"CLUSTER\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCNIK2lqkZjF"
   },
   "source": [
    "**Displaying the frequency of each value in every variable**\n",
    "\n",
    "We display the frequency of each value for some variables that have a big impact on the ELAPSEDTIME variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1603989867537,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "9WegsavKlYGC",
    "outputId": "38630f04-2b0c-4784-c960-2996f1c315c5"
   },
   "outputs": [],
   "source": [
    "HPC3['PERFORMANCE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1603989868650,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "Em22Jn5M_HrU",
    "outputId": "bb68eb1d-26be-43b1-d9db-3ce3582ced77"
   },
   "outputs": [],
   "source": [
    "HPC3['PRECISION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1603989868652,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "NtveeiGX_WQX",
    "outputId": "9c0cf77f-f79f-4651-ded8-faec8828b4ec"
   },
   "outputs": [],
   "source": [
    "HPC3['VERSION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1603989868997,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "86DrNP2A_lzR",
    "outputId": "62623847-429b-4de0-9c43-c334d907d6f6"
   },
   "outputs": [],
   "source": [
    "HPC3['NBSERVERS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wzf79Zymk9_O"
   },
   "source": [
    "### **Graphical displays to help have an intuition about the data**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48t8NZ2uaE8F"
   },
   "source": [
    "# Nouvelle section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-D1OuWNGGUt"
   },
   "outputs": [],
   "source": [
    "Pie_HPC3 = HPC3.copy()\n",
    "# Modify the dataset to add the cardinality in the column name.\n",
    "# Used only to display the pie charts\n",
    "perf = HPC3[\"PERFORMANCE\"].value_counts().to_dict()\n",
    "nbserv = HPC3[\"NBSERVERS\"].value_counts().to_dict()\n",
    "for key,value in perf.items():\n",
    "  perf[key] = key+\" : \"+str(perf[key])\n",
    "for key,value in nbserv.items():\n",
    "  nbserv[key] = str(key)+\" : \"+str(nbserv[key])\n",
    "Pie_HPC3 = Pie_HPC3.replace({\"PERFORMANCE\":perf})\n",
    "Pie_HPC3 = Pie_HPC3.replace({\"NBSERVERS\":nbserv})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQcrxBbolx5l"
   },
   "source": [
    "#### **Data Distribution**\n",
    "\n",
    "We use a PiePlot to display the proportion of each category of the PERFORMANCE and NBSERVERS variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 1251,
     "status": "ok",
     "timestamp": 1603989869641,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "l5ZGvZ0cDsTE",
    "outputId": "5ee0c7fc-ed70-47ce-bb35-499be6f0523a"
   },
   "outputs": [],
   "source": [
    "plot_pie(Pie_HPC3, \"PERFORMANCE\", \"Performance types : Occurences\")\n",
    "# TODO Donner les cardinalités, idem pour les graphes suivants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 2248,
     "status": "ok",
     "timestamp": 1603989870835,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "QKr6JVNBCidS",
    "outputId": "86626b4b-22ae-4e50-9c84-f9575a317ed5"
   },
   "outputs": [],
   "source": [
    "plot_pie(Pie_HPC3,\"NBSERVERS\",\"Servers : Occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5A2rtCOmi0e"
   },
   "source": [
    "**Discretization of continuous variables**\n",
    "\n",
    "We transform continuous data into discretized/categorical data, in order to have an intuition about the proportion of each category using the PiePlot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1603989870838,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "dzRmNy_3MgDJ",
    "outputId": "ff6ab7dc-c7fc-488b-d445-912f5d010d5e"
   },
   "outputs": [],
   "source": [
    "Pie_HPC3[\"ELAPSEDTIME_disc\"] = discretize(HPC3[\"ELAPSEDTIME\"], [5*3600, 7*3600, 10*3600, 12*3600, 18*3600, 24*3600])\n",
    "tab = [\"<5h\", \"<7h\", \"<10h\", \"<12h\", \"<18h\", \"<24h\", \">24h\"]\n",
    "elap = {}\n",
    "for i in range(len(tab)):\n",
    "  elap[i] = tab[i] + \" : \" + str(Pie_HPC3[\"ELAPSEDTIME_disc\"].value_counts()[i])\n",
    "Pie_HPC3 = Pie_HPC3.replace({\"ELAPSEDTIME_disc\":elap})\n",
    "plot_pie(Pie_HPC3, \"ELAPSEDTIME_disc\", \"ELAPSEDTIME : Occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F9OEYnkmuI9"
   },
   "source": [
    "#### **Correlation between features**\n",
    "\n",
    "HeatMap is a type of data visualization that shows the correlation between each two varaibles. In other words, we intend to see how much impact each variable has on the Output Variable (ELAPSEDTIME) and if there are two variables that tell the same information (getting rid of one of them in that case won't affect the results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP72EESwoOod"
   },
   "source": [
    "**Encoding categorical data**\n",
    "\n",
    "We need to transform categorical data into numerical data in order for the HeatMap to be able to use it. For example, we can represent this set of values [Yes, No] as [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDG6EYZVEoOt"
   },
   "outputs": [],
   "source": [
    "numerical = list(df.describe().columns)\n",
    "categorical = [col for col in df.columns if col not in numerical]\n",
    "for column in categorical:\n",
    "  df[column] = LabelEncoder().fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu4CgoQSor3y"
   },
   "source": [
    "**Visualizing the HeatMap and correlation table**\n",
    "\n",
    "The color of the field indicates the correlation's degree. Red is for positive correlation (incrementing variable1 increments variable2's value), Blue is negative correlation (incrementing varialbe1 decrements variable2's value), whilst white is neutral (no correlation = varialbe1 has no effect on variable2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1603990001163,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "LmB69VZMCZed",
    "outputId": "2a388d7f-606f-418f-c83b-f69ad6e0e197"
   },
   "outputs": [],
   "source": [
    "correl = df.corr(method = 'pearson')\n",
    "sns.set(rc={'figure.facecolor':'white'})\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "correl_final = sns.heatmap(correl, vmin = -1, vmax = 1, center = 0, cmap = \"RdBu_r\", square = True, ax=ax)\n",
    "correl_final.set_title('Correlation between features', fontsize = 25, loc = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1603990008593,
     "user": {
      "displayName": "Hamza Jebbar",
      "photoUrl": "",
      "userId": "15046422398258861357"
     },
     "user_tz": -60
    },
    "id": "OtMYpcT3CbGO",
    "outputId": "b83e424a-de0a-41da-82c5-f3bc842c2c65"
   },
   "outputs": [],
   "source": [
    "# Display the Heatmap's rounded values\n",
    "round(correl,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Analyze Dataset_BQ.ipynb",
   "provenance": [
    {
     "file_id": "1J1lofxH0PT58mEudlUnP2gPkOPCQ6etx",
     "timestamp": 1608220463090
    },
    {
     "file_id": "1dWIYCIKBkOI4T9hHtccYHBrcN3NoXWyq",
     "timestamp": 1601302811034
    }
   ]
  },
  "environment": {
   "name": "tf2-cpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
