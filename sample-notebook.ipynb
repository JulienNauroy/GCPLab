{"nbformat":4,"nbformat_minor":0,"metadata":{"environment":{"name":"tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"sample-notebook.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"tHF7K8ptOKyd"},"source":["# Sample Cloud AI Platform Notebook: Predicting Visitor Behaviour\n","Predict if a visitor will add items to the cart using their browsing session data"]},{"cell_type":"markdown","metadata":{"id":"GhPPnhS_OKyj"},"source":["# Import"]},{"cell_type":"code","metadata":{"id":"RJqWJZNZOKyk"},"source":["import os\n","import time\n","from datetime import datetime\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","from tensorflow import feature_column\n","import tensorflow_io as tfio"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uX1d-Oh3OKyl"},"source":["# Load and plot some data\n"]},{"cell_type":"markdown","metadata":{"id":"b13tNL4xOKyl"},"source":["Let's use the Google Cloud datawharehouse [BigQuery](https://cloud.google.com/bigquery/docs/introduction) to query the data.  \n","The BigQuery client library provides a cell magic ```%%bigquery``` which runs a SQL query and returns the results as a Pandas DataFrame.  \n","Use the cell magic to query a sample of data and save the results in the ```train_df``` DataFrame:"]},{"cell_type":"code","metadata":{"id":"pwiqKSb_OKyl"},"source":["%%bigquery train_df\n","SELECT \n","*\n","FROM\n","  `challenge.training_data`"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r_fniemoOKym"},"source":["Show the first few rows of the DataFrame:"]},{"cell_type":"code","metadata":{"id":"2brTRhBqOKym","outputId":"f92bdce0-1b04-4f16-97f6-69cce8bc01d6"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>JOBID</th>\n","      <th>DAY</th>\n","      <th>HOUR</th>\n","      <th>VERSION</th>\n","      <th>PERFORMANCE</th>\n","      <th>PRECISION</th>\n","      <th>MPLINK</th>\n","      <th>NTNU</th>\n","      <th>MPLINK_NTNU</th>\n","      <th>MBS</th>\n","      <th>...</th>\n","      <th>NBNODES</th>\n","      <th>NBELEM1D</th>\n","      <th>NBELEM2D</th>\n","      <th>NBELEM3D</th>\n","      <th>CLUSTER</th>\n","      <th>NBSERVERS</th>\n","      <th>NBCORE</th>\n","      <th>DATACHECK_TIME</th>\n","      <th>ELAPSEDTIME</th>\n","      <th>TZC_FINAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>972300</td>\n","      <td>03/03/2020</td>\n","      <td>17:50:30</td>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>...</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15000</td>\n","      <td>0.0114</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>975299</td>\n","      <td>03/04/2020</td>\n","      <td>09:38:09</td>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>...</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15600</td>\n","      <td>0.0114</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>993587</td>\n","      <td>03/06/2020</td>\n","      <td>10:53:17</td>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>...</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>14600</td>\n","      <td>0.0115</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>972300</td>\n","      <td>03/03/2020</td>\n","      <td>17:50:30</td>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>...</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15000</td>\n","      <td>0.0114</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>975299</td>\n","      <td>03/04/2020</td>\n","      <td>09:38:09</td>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>...</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15600</td>\n","      <td>0.0114</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["    JOBID         DAY      HOUR   VERSION PERFORMANCE  PRECISION MPLINK NTNU  \\\n","0  972300  03/03/2020  17:50:30  2018.0.1        POLE          1    YES   NO   \n","1  975299  03/04/2020  09:38:09  2018.0.1        POLE          1    YES   NO   \n","2  993587  03/06/2020  10:53:17  2018.0.1        POLE          1    YES   NO   \n","3  972300  03/03/2020  17:50:30  2018.0.1        POLE          1    YES   NO   \n","4  975299  03/04/2020  09:38:09  2018.0.1        POLE          1    YES   NO   \n","\n","  MPLINK_NTNU MBS  ...  NBNODES  NBELEM1D  NBELEM2D  NBELEM3D  CLUSTER  \\\n","0          NO  NO  ...  4507694     14570   4037272   1570802     HPC3   \n","1          NO  NO  ...  4507694     14570   4037272   1570802     HPC3   \n","2          NO  NO  ...  4507694     14570   4037272   1570802     HPC3   \n","3          NO  NO  ...  4507694     14570   4037272   1570802     HPC3   \n","4          NO  NO  ...  4507694     14570   4037272   1570802     HPC3   \n","\n","   NBSERVERS NBCORE  DATACHECK_TIME  ELAPSEDTIME  TZC_FINAL  \n","0        8.0    288           446.0        15000     0.0114  \n","1        8.0    288           446.0        15600     0.0114  \n","2        8.0    288           446.0        14600     0.0115  \n","3        8.0    288           446.0        15000     0.0114  \n","4        8.0    288           446.0        15600     0.0114  \n","\n","[5 rows x 22 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"MeS2lkC6OKyn"},"source":["Show the DataFrame details:"]},{"cell_type":"code","metadata":{"id":"o9prqHwmOKyo","outputId":"89c79017-53ee-48b4-d657-ea20d15260f6"},"source":["df = train_df.drop([\"JOBID\",\"DAY\",\"HOUR\",\"TZC_FINAL\"], axis=1)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VERSION</th>\n","      <th>PERFORMANCE</th>\n","      <th>PRECISION</th>\n","      <th>MPLINK</th>\n","      <th>NTNU</th>\n","      <th>MPLINK_NTNU</th>\n","      <th>MBS</th>\n","      <th>RUNEND</th>\n","      <th>TIMESTEP</th>\n","      <th>NBNODES</th>\n","      <th>NBELEM1D</th>\n","      <th>NBELEM2D</th>\n","      <th>NBELEM3D</th>\n","      <th>CLUSTER</th>\n","      <th>NBSERVERS</th>\n","      <th>NBCORE</th>\n","      <th>DATACHECK_TIME</th>\n","      <th>ELAPSEDTIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>110.01</td>\n","      <td>0.0005</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>110.01</td>\n","      <td>0.0005</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15600</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>110.01</td>\n","      <td>0.0005</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>14600</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>110.01</td>\n","      <td>0.0005</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018.0.1</td>\n","      <td>POLE</td>\n","      <td>1</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>110.01</td>\n","      <td>0.0005</td>\n","      <td>4507694</td>\n","      <td>14570</td>\n","      <td>4037272</td>\n","      <td>1570802</td>\n","      <td>HPC3</td>\n","      <td>8.0</td>\n","      <td>288</td>\n","      <td>446.0</td>\n","      <td>15600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    VERSION PERFORMANCE  PRECISION MPLINK NTNU MPLINK_NTNU MBS  RUNEND  \\\n","0  2018.0.1        POLE          1    YES   NO          NO  NO  110.01   \n","1  2018.0.1        POLE          1    YES   NO          NO  NO  110.01   \n","2  2018.0.1        POLE          1    YES   NO          NO  NO  110.01   \n","3  2018.0.1        POLE          1    YES   NO          NO  NO  110.01   \n","4  2018.0.1        POLE          1    YES   NO          NO  NO  110.01   \n","\n","   TIMESTEP  NBNODES  NBELEM1D  NBELEM2D  NBELEM3D CLUSTER  NBSERVERS  NBCORE  \\\n","0    0.0005  4507694     14570   4037272   1570802    HPC3        8.0     288   \n","1    0.0005  4507694     14570   4037272   1570802    HPC3        8.0     288   \n","2    0.0005  4507694     14570   4037272   1570802    HPC3        8.0     288   \n","3    0.0005  4507694     14570   4037272   1570802    HPC3        8.0     288   \n","4    0.0005  4507694     14570   4037272   1570802    HPC3        8.0     288   \n","\n","   DATACHECK_TIME  ELAPSEDTIME  \n","0           446.0        15000  \n","1           446.0        15600  \n","2           446.0        14600  \n","3           446.0        15000  \n","4           446.0        15600  "]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"UE_z1L3DOKyo","outputId":"11194f8d-971a-4de3-e7f3-01015e034fde"},"source":["print(df.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Index(['VERSION', 'PERFORMANCE', 'PRECISION', 'MPLINK', 'NTNU', 'MPLINK_NTNU',\n","       'MBS', 'RUNEND', 'TIMESTEP', 'NBNODES', 'NBELEM1D', 'NBELEM2D',\n","       'NBELEM3D', 'CLUSTER', 'NBSERVERS', 'NBCORE', 'DATACHECK_TIME',\n","       'ELAPSEDTIME'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"APyZNoQFOKyo"},"source":["printing catagorical and numerical features"]},{"cell_type":"code","metadata":{"id":"tLfqilQ2OKyp"},"source":["numerical = list(df.describe().columns)\n","categorical = [col for col in df.columns if col not in numerical]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGGEjALFOKyp","outputId":"eba04943-acc3-4601-ed9b-90fa957a1a03"},"source":["print(categorical)\n","print(numerical)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['VERSION', 'PERFORMANCE', 'MPLINK', 'NTNU', 'MPLINK_NTNU', 'MBS', 'CLUSTER']\n","['PRECISION', 'RUNEND', 'TIMESTEP', 'NBNODES', 'NBELEM1D', 'NBELEM2D', 'NBELEM3D', 'NBSERVERS', 'NBCORE', 'DATACHECK_TIME', 'ELAPSEDTIME']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KGj0BLN2Op86"},"source":["Show unique values for each catagorical features"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"0wWbDJygOKyp","executionInfo":{"status":"error","timestamp":1612176806937,"user_tz":-60,"elapsed":520,"user":{"displayName":"Aurélien Galicher","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqTtOOiEo05zGER22O3SrHzEVPVJ04tJDKf6kP=s64","userId":"09808616516538419425"}},"outputId":"744ddd60-166d-4a7d-e05f-58ca9e8d179b"},"source":["df[categorical].describe()\n","for x in categorical:\n","    print ({x: list(df[x].unique())})"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-68ea8d219c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"ynh_GH2bOKyq"},"source":["# Local training"]},{"cell_type":"markdown","metadata":{"id":"Tqkd3mgUOKyq"},"source":["First, let's try to train the model locally (from within the notebook)."]},{"cell_type":"markdown","metadata":{"id":"fv2uyGuZOKyq"},"source":["## Create a Google Cloud Storage bucket"]},{"cell_type":"markdown","metadata":{"id":"rD_cEQobOKyr"},"source":["We need a way to centrally store and share data across services.  \n","Let's use [Google Cloud Storage](https://cloud.google.com/storage) which is the blob storage service from Google Cloud."]},{"cell_type":"markdown","metadata":{"id":"vkP8zKu-OKyr"},"source":["```gsutil``` is a command line tool for Google Cloud Storage.  \n","In Google Cloud Storage, URI are in the format ```gs://bucket/folder/file``` .  \n","Use ```gsutil mb gs://YourBucketName``` to create a Google Cloud Storage bucket.\n","\n","Your bucket name must be **globally** unique and must contain only lowercase letters, numbers, dashes, underscores, and dots.  \n","**!!! Change the bucket name below with your own!!!**"]},{"cell_type":"code","metadata":{"id":"efaxbwq5OKyr","outputId":"36503f3a-a0fe-480a-a03d-8d1a8a5ff111"},"source":["# Prepare Google Cloud Storage directory to save logs and model\n","BUCKET_NAME = 'ml-competition-001' # Create your own unique bucket name\n","!gsutil mb -l EU gs://{BUCKET_NAME}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating gs://ml-competition-001/...\n","ServiceException: 409 Bucket ml-competition-001 already exists.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6yr_YrxZOKys"},"source":["Use ```gsutil ls gs://YourBucketName``` to list your bucket and make sure it has been correctly created.  \n","Expect no output if the bucket is correctly created."]},{"cell_type":"code","metadata":{"id":"90MX2IsQOKys","outputId":"94643123-8a99-4138-cd98-ebc9e47c4ff5"},"source":["!gsutil ls gs://{BUCKET_NAME}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gs://ml-competition-001/latest_model/\n","gs://ml-competition-001/training_job_2021_01_29_170545/\n","gs://ml-competition-001/training_job_2021_01_29_172946/\n","gs://ml-competition-001/training_job_2021_01_31_143525/\n","gs://ml-competition-001/training_job_2021_01_31_144654/\n","gs://ml-competition-001/training_job_2021_01_31_145423/\n","gs://ml-competition-001/training_job_2021_01_31_150103/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4gmMzOGYOKys"},"source":["## Create your trainer package structure"]},{"cell_type":"markdown","metadata":{"id":"sICzp_Z4OKyt"},"source":["Now let's create your trainer package structure."]},{"cell_type":"code","metadata":{"id":"FHCYtF7FOKyt","outputId":"9f731352-e828-40ee-d0a8-cf1830ec3dd2"},"source":["# Create the Trainer package structure\n","!mkdir ./trainer\n","!touch ./trainer/__init__.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘./trainer’: File exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mz00P28uOKyv"},"source":["**!!! Change the bucket name below with your own!!!**"]},{"cell_type":"code","metadata":{"id":"lA2utUPUOKyv","outputId":"f8ae3df0-f598-400c-9a3c-98a441f25365"},"source":["%%writefile ./trainer/task.py\n","\n","# Imports\n","import os\n","import pandas as pd\n","import tensorflow as tf\n","from google.cloud import bigquery\n","from sklearn.model_selection import train_test_split\n","\n","# Declare constants\n","BUCKET_NAME = 'ml-competition-001'  # change to YOUR bucket name\n","JOB_DIR = f'gs://{BUCKET_NAME}/latest_model' \n","CATEGORICAL_TYPES = {'VERSION': pd.api.types.CategoricalDtype(['2018.0.1', '2016.05', '2016.06', '2019.0.2', '2012.7', '2019.0', '2018.0', '2016.01', '2019.0.1', '2019']),\n","                     'PERFORMANCE': pd.api.types.CategoricalDtype(['POLE', 'PEDESTRIAN', 'UNKNOWN', 'ECE', 'FRONT', 'RCAR', 'COCKPIT', 'OVERSLAM', 'REAR', 'SIDE', 'WHEEL']),\n","                    'MPLINK': pd.api.types.CategoricalDtype(['YES', 'NO']),\n","                    'NTNU': pd.api.types.CategoricalDtype(['NO', 'YES']),\n","                    'MPLINK_NTNU': pd.api.types.CategoricalDtype(['NO', 'YES']),\n","                    'MBS': pd.api.types.CategoricalDtype(['NO', 'USED']),\n","                    'CLUSTER':pd.api.types.CategoricalDtype(['HPC3', 'HPC1', 'HPC2'])}\n","                                                              \n","TARGET_COLUMN = 'ELAPSEDTIME'\n","QUERY = '''SELECT \n","       VERSION, PERFORMANCE, PRECISION, MPLINK, NTNU, MPLINK_NTNU,\n","       MBS, RUNEND, TIMESTEP, NBNODES, NBELEM1D, NBELEM2D,\n","       NBELEM3D, CLUSTER, NBSERVERS, NBCORE, DATACHECK_TIME,\n","       ELAPSEDTIME\n","FROM\n","  `demoairenault.challenge.training_data`'''\n","\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 5\n","LEARNING_RATE = 0.001\n","\n","# Read the data from BigQuery\n","client = bigquery.Client(location='EU') \n","query_job = client.query(QUERY)\n","data_df = query_job.to_dataframe()  # you can read from other sources to pandas DataFrame\n","print(f'First rows for the raw dataset: \\n{data_df.head()}')\n","\n","# Convert integer valued (numeric) columns to floating point\n","numeric_columns = data_df.select_dtypes(['int64']).columns\n","data_df[numeric_columns] = data_df[numeric_columns].astype('float32')\n","\n","# Convert categorical columns to numeric\n","cat_columns = data_df.select_dtypes(['object']).columns\n","data_df[cat_columns] = data_df[cat_columns].astype('category')\n","data_df[cat_columns] = data_df[cat_columns].apply(lambda x: x.astype(\n","        CATEGORICAL_TYPES[x.name]))\n","data_df[cat_columns] = data_df[cat_columns].apply(lambda x: x.cat.codes)\n","print(f'First rows for the transformed dataset: \\n{data_df.head()}')\n","\n","# Train/Val split\n","train_df, val_df = train_test_split(data_df, train_size=0.8)\n","train_target = train_df.pop(TARGET_COLUMN)\n","val_target = val_df.pop(TARGET_COLUMN)\n","num_train_examples = len(train_df)\n","num_val_examples = len(val_df)\n","\n","# *Possible improvements*: add standartization for numeric values to range [-1; 1], categories to one-hot encoded\n","\n","# Creata tensorflow dataset object\n","dataset_train = (tf.data.Dataset\n","                 .from_tensor_slices((train_df.to_dict('list'), train_target))\n","                 .shuffle(buffer_size=BATCH_SIZE*4)\n","                 .repeat()\n","                 .batch(BATCH_SIZE))\n","                 \n","dataset_val = (tf.data.Dataset\n","                 .from_tensor_slices((val_df.to_dict('list'), val_target))\n","                 .repeat()\n","                 .batch(BATCH_SIZE))  # No shuffle\n","\n","print(f'One batch of the train data:\\n {next(iter(dataset_train))}')\n","\n","# Prepare named inputs for our model\n","inputs = {key: tf.keras.layers.Input(shape=(), name=key) for key in train_df.keys()}\n","x = tf.stack(list(inputs.values()), axis=-1)\n","\n","# Define model's architecture\n","x = tf.keras.layers.Dense(100, activation='relu')(x)\n","x = tf.keras.layers.Dense(50, activation='relu')(x)\n","x = tf.keras.layers.Dense(10, activation='relu')(x)\n","output = tf.keras.layers.Dense(1, activation='linear')(x)\n","\n","# Build the model and compile it\n","model_func = tf.keras.Model(inputs=inputs, outputs=output)\n","model_func.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n","                   loss='mean_absolute_error')\n","\n","# Train the model\n","history = model_func.fit(dataset_train, \n","                          epochs=NUM_EPOCHS, \n","                          steps_per_epoch=int(num_train_examples/BATCH_SIZE), \n","                          validation_data=dataset_val, \n","                          validation_steps=int(num_train_examples/BATCH_SIZE), \n","                          verbose=1)\n","\n","model_func.save(f'{JOB_DIR}/export/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting ./trainer/task.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jur6q1OPOKyx","outputId":"0b371fe5-301c-474a-a768-cc5d29aab790"},"source":["%%writefile ./setup.py\n","from setuptools import find_packages\n","from setuptools import setup\n","\n","REQUIRED_PACKAGES = ['scikit-learn', 'pandas']\n","\n","setup(\n","    name='trainer',\n","    version='0.1',\n","    install_requires=REQUIRED_PACKAGES,\n","    packages=find_packages(),\n","    include_package_data=True,\n","    description='My super training application package.'\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting ./setup.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c2aZrtEpOKyy"},"source":["## Run a local training task\n","This is a good test before your will try to train the model in the cloud"]},{"cell_type":"markdown","metadata":{"id":"FzEAON-YOKyy"},"source":["Many commands we are going to use accept a parameter for setting a region.  \n","A region is a group of Google Cloud data centers used to run computing tasks.  \n","To reduce latency, let's set a variable with a close by data center:"]},{"cell_type":"code","metadata":{"id":"LzwTIu5YOKyy"},"source":["REGION = 'europe-west1'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JtNY767rOKyz"},"source":["For interacting with Cloud AI Platform we are going to use the [gcloud](https://cloud.google.com/sdk/gcloud) command line tool.  \n","Gcloud also provides [properties](https://cloud.google.com/sdk/docs/properties) used by other services.  \n","Let's set the __ml_engine/local_python__ property so AI Platform knows which Python version to use for local training:"]},{"cell_type":"code","metadata":{"id":"To-Lp-rwOKyz","outputId":"200613d1-74d6-4b77-ef0e-96e648123b9a"},"source":["# Explicitly tell `gcloud ai-platform local train` to use Python 3 \n","!gcloud config set ml_engine/local_python $(which python3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Updated property [ml_engine/local_python].\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uhbRp9tJOKyz"},"source":["For submitting a local training job to AI Platform you need to provide:\n","* A directory to store the model and logs: here we are going to use our Google Cloud Storage bucket we created earlier\n","* The path to your trainer package\n","* The name of your trainer module"]},{"cell_type":"code","metadata":{"id":"Ew_A_jr7OKy0","outputId":"3c13e3ba-7e97-4e22-8db0-c6914c219e6d"},"source":["# Define a timestamped job name\n","JOB_NAME = f\"training_job_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"; print(JOB_NAME)\n","JOB_DIR = f'gs://{BUCKET_NAME}/{JOB_NAME}'; print(JOB_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["training_job_2021_01_31_154624\n","gs://ml-competition-001/training_job_2021_01_31_154624\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tMVitxfVOKy0"},"source":["Let's run our local training job with the gcloud command ```gcloud ai-platform local train```."]},{"cell_type":"code","metadata":{"id":"ayXRyxxnOKy0","outputId":"8e2c6e44-da2e-430a-f9f9-5952c284d96c"},"source":["# Run the localtraining job\n","! gcloud ai-platform local train \\\n","  --job-dir $JOB_DIR \\\n","  --package-path ./trainer \\\n","  --module-name trainer.task "],"execution_count":null,"outputs":[{"output_type":"stream","text":["First rows for the raw dataset: \n","    VERSION PERFORMANCE  PRECISION  ... NBCORE DATACHECK_TIME ELAPSEDTIME\n","0  2018.0.1        POLE          1  ...    288          446.0       15000\n","1  2018.0.1        POLE          1  ...    288          446.0       15600\n","2  2018.0.1        POLE          1  ...    288          446.0       14600\n","3  2018.0.1        POLE          1  ...    288          446.0       15000\n","4  2018.0.1        POLE          1  ...    288          446.0       15600\n","\n","[5 rows x 18 columns]\n","First rows for the transformed dataset: \n","   VERSION  PERFORMANCE  PRECISION  ...  NBCORE  DATACHECK_TIME  ELAPSEDTIME\n","0        0            0        1.0  ...   288.0           446.0      15000.0\n","1        0            0        1.0  ...   288.0           446.0      15600.0\n","2        0            0        1.0  ...   288.0           446.0      14600.0\n","3        0            0        1.0  ...   288.0           446.0      15000.0\n","4        0            0        1.0  ...   288.0           446.0      15600.0\n","\n","[5 rows x 18 columns]\n","2021-01-31 15:46:43.220368: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\n","2021-01-31 15:46:43.229345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626d7cbb7e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-01-31 15:46:43.229380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-01-31 15:46:43.235320: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","One batch of the train data:\n"," ({'VERSION': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([1, 1, 1, 0, 1, 1, 1, 3, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n","       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 1, 0, 1, 1, 4, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 4, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 4, 0, 1, 1, 1], dtype=int32)>, 'PERFORMANCE': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([ 8,  0,  3,  6,  2,  1,  2,  2,  2,  1,  2,  4,  3,  2,  4,  6,  4,\n","        1,  9,  6,  1,  2,  2,  1,  4,  6,  6,  6,  2,  2,  4,  2,  2,  1,\n","        1,  3,  1,  2,  4,  1,  2,  2,  3,  1,  2,  1,  4,  7,  2,  6,  2,\n","        1,  4,  2,  7,  2,  2,  2,  6,  4,  8,  3,  3,  6,  2,  6,  6,  6,\n","        2,  1,  7,  2,  1,  4,  2,  4,  6,  2,  2,  2,  2,  2,  3,  4,  2,\n","        5,  2,  2,  2,  1,  4,  2,  1,  8,  2,  2,  2,  2,  4,  1,  2,  2,\n","        2,  4,  1,  3,  4,  9,  2,  7,  4,  8,  1,  6,  4,  2, 10,  2,  1,\n","        5,  4,  2,  4,  1,  2,  1,  3,  2], dtype=int32)>, 'PRECISION': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1.,\n","       1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, 'MPLINK': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int32)>, 'NTNU': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'MPLINK_NTNU': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int32)>, 'MBS': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'RUNEND': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([ 150.01,   55.01,  350.01,  150.  ,  180.  ,   35.01,  150.1 ,\n","        200.01,  100.01,   35.01, 1200.  ,  120.  ,  200.01,  250.01,\n","        100.01,  120.  ,  150.01,   32.01,  210.01,  150.01,   40.1 ,\n","        200.1 ,   80.1 ,   32.01,  140.01,  200.  ,  150.  ,  120.  ,\n","         15.01,  160.01,  130.01,  100.01,   70.01,   35.01,   50.01,\n","        450.01,   50.01,  150.1 ,  120.01,   40.01,   50.01,   80.01,\n","        450.01,   50.01,  100.01,   35.01,  130.01,  100.1 ,   90.01,\n","        150.  ,   79.  ,   40.1 ,  120.01,  120.  ,  100.  ,  110.01,\n","        300.01,   80.1 ,  150.01,  121.01,  150.01,  450.  ,  250.1 ,\n","        200.  ,  100.  ,  120.  ,  130.  ,  200.  ,  150.01,   32.01,\n","        110.  ,  100.01,   50.01,  150.01,   50.01,   60.01,  200.  ,\n","         80.01,  100.  ,  100.  ,  150.  , 1200.  ,  150.01,  120.01,\n","         80.1 ,  200.01,   30.1 ,  100.01,  100.1 ,   40.1 ,  130.01,\n","        150.01,   80.  ,  150.01,   80.1 ,  150.  ,  457.21,  460.1 ,\n","        120.01,   50.01,  200.1 ,  200.01,  450.  ,  120.01,   34.01,\n","        200.  ,  130.01,  100.  ,  200.1 ,  120.  ,  100.01,  120.01,\n","         50.01,  200.  ,  100.01,  140.1 , 3500.1 ,  180.01,   40.01,\n","        150.01,  150.01,  250.01,  160.01,   35.01,  160.01,   40.01,\n","        160.01,   70.01], dtype=float32)>, 'TIMESTEP': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 1.00e-03, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 7.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 4.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 7.00e-04, 5.00e-04,\n","       5.00e-04, 4.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       4.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 3.33e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 4.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 1.00e-03, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 6.00e-04, 5.00e-04, 2.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 3.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 4.00e-04, 5.00e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 4.00e-05, 1.50e-04, 5.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04, 5.00e-04, 7.00e-04, 5.00e-04, 5.00e-04,\n","       5.00e-04, 5.00e-04], dtype=float32)>, 'NBNODES': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([4733785., 3239367., 1188338., 1049280.,  154028., 2139608.,\n","        342811., 2841616., 4610668., 1335003.,  235947., 3528827.,\n","       1631944., 4860377., 4007590.,  417225., 4528391., 2476700.,\n","       6075611.,  541614., 1973147.,  430148.,  617087., 2440160.,\n","       5602589.,  104466.,  178643.,  339286., 3567915., 5882381.,\n","       6659830., 5116226., 5519903., 2139608., 2166828., 1461914.,\n","       1255570.,  452250., 4576371., 1709798., 6324946.,  715192.,\n","       1461914., 1151257., 4142150., 2139608., 4450984.,  902361.,\n","       4509676.,  400583.,  431448., 1973147., 6959975.,  344378.,\n","        670990., 8256633.,  120811.,  616413.,  609516., 4890532.,\n","       5311864., 2144969., 2131396.,  747668., 1259645.,  487377.,\n","        806542.,  350678., 5293266., 2322987.,  578144., 4144182.,\n","       1330111., 4728279., 6479765., 5607295.,  481646., 2038691.,\n","       6024138., 6024120.,  313300.,  186365.,  714719., 4797709.,\n","        618476.,  929645.,  926098., 1258481.,  275166., 2034614.,\n","       3366525.,  222976., 1629526., 3932173.,  617087.,  308047.,\n","       3409865., 1280111., 4789937., 1504433.,  100581.,  534167.,\n","       1469449., 7687832., 2439909.,  997239., 6660369., 3683869.,\n","        321198.,  593626., 7372245., 4793874., 1283811.,  747668.,\n","       4983774.,  398748.,  811462., 1359872., 1703608., 4564291.,\n","       6433361., 4860377., 8623265., 1284429., 6523637., 1699836.,\n","       1126726., 2320943.], dtype=float32)>, 'NBELEM1D': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([1.6471e+04, 1.2823e+04, 5.1540e+03, 6.9600e+03, 2.7920e+03,\n","       4.2330e+03, 3.5710e+03, 7.5690e+03, 1.7027e+04, 2.7320e+03,\n","       2.9800e+02, 1.6380e+04, 1.0565e+04, 1.8171e+04, 1.4770e+04,\n","       1.1100e+03, 1.0154e+04, 6.0580e+03, 2.2214e+04, 2.4590e+03,\n","       6.6700e+03, 1.3690e+03, 2.0450e+03, 6.2360e+03, 1.7057e+04,\n","       6.2700e+02, 7.8100e+02, 7.3200e+02, 8.4530e+03, 1.6843e+04,\n","       1.9585e+04, 1.6330e+04, 1.8234e+04, 4.2330e+03, 6.4580e+03,\n","       6.8220e+03, 4.3620e+03, 1.4880e+03, 1.8647e+04, 4.8120e+03,\n","       2.0842e+04, 2.6720e+03, 6.8220e+03, 4.1990e+03, 2.1662e+04,\n","       4.2330e+03, 1.4601e+04, 2.7360e+03, 1.3637e+04, 1.1520e+03,\n","       3.4880e+03, 6.6700e+03, 1.8163e+04, 7.2800e+02, 2.1260e+03,\n","       1.8515e+04, 2.8020e+03, 2.0440e+03, 2.3850e+03, 2.1491e+04,\n","       1.9598e+04, 9.9120e+03, 1.1023e+04, 3.7380e+03, 5.9590e+03,\n","       2.0580e+03, 3.1950e+03, 1.6380e+03, 1.5143e+04, 5.7730e+03,\n","       1.0030e+03, 1.8080e+04, 4.3330e+03, 2.0024e+04, 2.2438e+04,\n","       1.7056e+04, 1.9680e+03, 6.0080e+03, 2.0970e+04, 2.0934e+04,\n","       2.7530e+03, 3.7280e+03, 1.8510e+03, 1.9188e+04, 2.0460e+03,\n","       1.6950e+03, 1.6900e+03, 3.5010e+03, 1.2000e+01, 6.6700e+03,\n","       1.6021e+04, 2.8600e+02, 3.3790e+03, 1.3049e+04, 2.0450e+03,\n","       2.2510e+03, 8.9670e+03, 3.7620e+03, 1.9039e+04, 4.3630e+03,\n","       1.3130e+03, 7.9610e+03, 6.2950e+03, 2.0045e+04, 5.8800e+03,\n","       2.2510e+03, 1.9585e+04, 1.8902e+04, 2.2790e+03, 1.4050e+03,\n","       1.7574e+04, 1.2999e+04, 4.2570e+03, 3.7380e+03, 1.1678e+04,\n","       5.1000e+01, 6.3487e+04, 2.8230e+03, 4.7620e+03, 1.4277e+04,\n","       2.3699e+04, 1.8171e+04, 2.0578e+04, 2.4130e+03, 2.1695e+04,\n","       4.7620e+03, 7.7940e+03, 5.4250e+03], dtype=float32)>, 'NBELEM2D': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([4658322., 2914068., 1149677.,  842663.,  148621., 2145605.,\n","        297826., 2760411., 4510651., 1351929.,   33214., 3359335.,\n","       1585851., 4571980., 3192916.,  312592., 3930266., 2202514.,\n","       5747970.,  360445., 1662962.,  417724.,  359230., 2161338.,\n","       4713377.,   12200.,  166088.,  101318., 3450865., 5565109.,\n","       6575282., 4836434., 5243318., 2145605., 1779316., 1410292.,\n","        947145.,  437111., 4439859., 1454422., 5695330.,  695692.,\n","       1410292.,  868450., 3715390., 2145605., 4440588.,  890716.,\n","       4087653.,  300053.,  350678., 1662962., 6682928.,  105165.,\n","        652863., 8101422.,  103905.,  358639.,  429518., 4694134.,\n","       5205459., 2110495., 2042158.,  495851.,  520423.,  280540.,\n","        572850.,  329634., 4352251., 2044437.,  561028., 3685895.,\n","       1029142., 4562119., 5829322., 4717951.,  371571., 1838959.,\n","       5295283., 5295292.,   99936.,  144469.,  701032., 4730157.,\n","        360534.,  775436.,  787424., 1266637.,   22744., 1662962.,\n","       3223126.,   21026., 1665900., 3904178.,  359230.,  239192.,\n","       3302680., 1249050., 4720774., 1239892.,   49272.,  460661.,\n","       1425731., 7316086., 2171270.,  972943., 6575588., 3677316.,\n","         99835.,  579592., 6924315., 4099223.,  970745.,  495851.,\n","       4823913.,       0.,  231830., 1396186., 1448492., 4316615.,\n","       5880473., 4571980., 7820290., 1135640., 5576250., 1445068.,\n","       1100459., 2236520.], dtype=float32)>, 'NBELEM3D': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([5.382760e+05, 7.770330e+05, 1.004000e+03, 5.843600e+05,\n","       2.286320e+05, 1.080570e+05, 3.285510e+05, 2.938900e+04,\n","       5.248660e+05, 1.549600e+04, 1.662270e+05, 1.199311e+06,\n","       2.072160e+05, 8.337990e+05, 1.446396e+06, 4.051790e+05,\n","       1.907383e+06, 3.124580e+05, 2.090752e+06, 2.739770e+05,\n","       4.048970e+05, 2.050000e+02, 3.155690e+05, 3.130230e+05,\n","       2.415329e+06, 8.304700e+04, 4.504000e+03, 3.100160e+05,\n","       3.069000e+03, 1.005043e+06, 4.057120e+05, 1.617166e+06,\n","       1.538201e+06, 1.080570e+05, 7.787500e+05, 1.933210e+05,\n","       2.345210e+05, 4.370000e+02, 6.490530e+05, 2.101840e+05,\n","       1.543579e+06, 9.231000e+03, 1.933210e+05, 2.105680e+05,\n","       9.638500e+05, 1.080570e+05, 3.745520e+05, 2.220000e+03,\n","       1.348037e+06, 2.942910e+05, 1.627530e+05, 4.048970e+05,\n","       1.777783e+06, 3.100140e+05, 5.680000e+02, 8.020910e+05,\n","       5.476200e+04, 3.155690e+05, 2.739790e+05, 1.061622e+06,\n","       6.679270e+05, 4.159800e+05, 2.047470e+05, 4.734550e+05,\n","       1.665651e+06, 2.987300e+05, 3.385100e+05, 1.005660e+05,\n","       1.709560e+06, 3.130230e+05, 5.860000e+02, 8.797310e+05,\n","       2.769830e+05, 1.534180e+06, 2.180928e+06, 2.415329e+06,\n","       1.893440e+05, 6.960540e+05, 1.740557e+06, 1.740557e+06,\n","       2.957840e+05, 1.223850e+05, 7.460000e+02, 5.968190e+05,\n","       3.155690e+05, 3.340930e+05, 3.107430e+05, 8.674600e+04,\n","       1.139075e+06, 7.233450e+05, 1.186573e+06, 1.662270e+05,\n","       2.421800e+04, 4.614660e+05, 3.155690e+05, 1.333740e+05,\n","       4.000000e+03, 6.450000e+02, 5.968190e+05, 2.204630e+05,\n","       3.209500e+04, 9.165500e+04, 2.301290e+05, 1.607238e+06,\n","       3.088090e+05, 2.926200e+04, 4.057120e+05, 9.108080e+05,\n","       2.641570e+05, 3.870000e+02, 1.277847e+06, 1.973115e+06,\n","       2.345260e+05, 4.734550e+05, 5.379170e+05, 3.728700e+05,\n","       7.558360e+05, 1.402500e+04, 2.101840e+05, 1.443084e+06,\n","       1.920699e+06, 8.337990e+05, 2.255169e+06, 5.042980e+05,\n","       2.748587e+06, 2.101840e+05, 2.201240e+05, 4.115540e+05],\n","      dtype=float32)>, 'CLUSTER': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n","array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n","       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1], dtype=int32)>, 'NBSERVERS': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([5., 5., 2., 2., 2., 2., 2., 2., 3., 2., 2., 4., 2., 5., 3., 2., 6.,\n","       2., 5., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 5., 4., 5., 3., 2.,\n","       2., 2., 2., 2., 4., 2., 5., 2., 2., 2., 3., 2., 6., 2., 5., 2., 2.,\n","       2., 5., 2., 2., 5., 2., 2., 2., 6., 5., 2., 2., 2., 2., 2., 2., 2.,\n","       5., 2., 2., 5., 2., 3., 5., 5., 2., 2., 5., 5., 2., 2., 2., 6., 2.,\n","       2., 2., 2., 2., 2., 6., 2., 2., 3., 2., 2., 2., 2., 4., 2., 2., 2.,\n","       2., 4., 2., 2., 4., 5., 2., 2., 5., 5., 2., 2., 3., 2., 3., 2., 2.,\n","       5., 4., 5., 6., 2., 5., 2., 2., 2.], dtype=float32)>, 'NBCORE': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([180., 180.,  48.,  48.,  48.,  48.,  48.,  48., 108.,  48.,  48.,\n","       144.,  48., 180., 108.,  48., 216.,  48., 180.,  48.,  48.,  48.,\n","        48.,  48., 108.,  48.,  48.,  48.,  48., 180., 144., 180., 108.,\n","        48.,  48.,  48.,  48.,  48., 144.,  48., 180.,  48.,  48.,  48.,\n","       108.,  48., 216.,  48., 180.,  48.,  48.,  48., 180.,  48.,  48.,\n","       180.,  48.,  48.,  48., 216., 180.,  48.,  48.,  48.,  48.,  48.,\n","        48.,  48., 180.,  48.,  48., 180.,  48., 108., 180., 180.,  48.,\n","        48., 180., 180.,  48.,  48.,  48., 216.,  48.,  48.,  48.,  48.,\n","        48.,  48., 216.,  48.,  48., 108.,  48.,  48.,  48.,  48., 144.,\n","        48.,  48.,  48.,  48., 144.,  48.,  48., 144., 180.,  48.,  48.,\n","       180., 180.,  48.,  48., 108.,  48., 108.,  48.,  48., 180., 144.,\n","       180., 216.,  48., 180.,  48.,  48.,  48.], dtype=float32)>, 'DATACHECK_TIME': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([396.  , 267.  ,  39.4 ,  55.6 ,   7.75, 108.  ,  14.2 ,  74.2 ,\n","       488.  ,  67.2 ,  13.5 , 341.  ,  72.1 , 431.  , 471.  ,  32.3 ,\n","       203.  , 176.  , 621.  ,  39.9 , 113.  ,  14.1 ,  48.6 , 167.  ,\n","       798.  ,   8.46,   6.1 ,  14.  ,  82.9 , 674.  , 440.  , 503.  ,\n","       468.  , 108.  , 130.  ,  69.  ,  70.3 ,  14.1 , 359.  , 105.  ,\n","       487.  ,  19.4 ,  68.6 ,  62.4 , 392.  , 107.  , 242.  ,  34.9 ,\n","       271.  ,  26.6 ,  21.5 , 113.  , 636.  ,  12.9 ,  28.9 , 944.  ,\n","         4.85,  49.9 ,  45.3 , 370.  , 476.  , 134.  , 165.  ,  31.3 ,\n","        64.7 ,  59.1 ,  67.8 ,  18.8 , 473.  , 183.  ,  18.1 , 361.  ,\n","        76.5 , 378.  , 576.  , 719.  ,  39.7 , 121.  , 711.  , 710.  ,\n","        11.8 ,  38.7 ,  20.4 , 408.  ,  40.5 ,  34.4 ,  26.8 ,  51.  ,\n","        19.4 , 122.  , 319.  ,   5.78,  81.5 , 327.  ,  52.5 ,  14.8 ,\n","       145.  ,  42.  , 507.  ,  90.4 ,   4.64,  14.8 ,  69.  , 650.  ,\n","       166.  ,  38.7 , 440.  , 248.  ,  17.9 ,  29.3 , 674.  , 513.  ,\n","        85.6 ,  31.2 , 341.  ,  12.9 ,  31.3 ,  56.  ,  82.7 , 421.  ,\n","       535.  , 436.  , 662.  ,  63.7 , 763.  ,  91.4 ,  63.  , 143.  ],\n","      dtype=float32)>}, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([ 19800.,   6860.,  25600.,  13900.,   2310.,   4670.,   4230.,\n","        31300.,  18100.,   2910.,  14400.,  20900.,  21100.,  37200.,\n","        16900.,   5980.,  12100.,   6110.,  42400.,   5780.,   5920.,\n","         8390.,   6320.,   6200.,  50900.,   1890.,   4310.,   6660.,\n","         3630.,  32100.,  28900.,  25000.,  16200.,   4930.,   6390.,\n","        56500.,   4790.,   6600.,  17400.,   5490.,   8570.,   4100.,\n","        52800.,   5070.,  21800.,   4920.,  14300.,   6460.,  14500.,\n","         9240.,   3780.,   5940.,  38000.,   8470.,  10500.,  26200.,\n","         3330.,   6340.,   9330.,  20500.,  21000.,  67800.,  40800.,\n","        19000.,  29400.,  11500.,  10800.,   5160.,  33300.,   6020.,\n","         9070.,  27100.,   4550.,  39400.,  15300.,  19200.,   9490.,\n","        13400.,  29800.,  29600.,   7030.,   8990.,   7310.,  17100.,\n","         6260.,  11400.,   2390.,   8500.,   3270.,   6360.,  22100.,\n","         2240.,   9340.,  20100.,   6230.,   7110., 101000.,  44200.,\n","        20100.,   7000.,   4990.,   6070.,  51800.,  37200.,   6360.,\n","        13500.,  30100.,  11400.,   3690.,  11000.,  67400.,  15400.,\n","         4600.,  19200.,  15700.,  34200., 125000.,  16000.,   5720.,\n","        17800.,  46800.,  40900.,  56500.,   2980.,  44900.,   5780.,\n","        14700.,  14700.], dtype=float32)>)\n","Epoch 1/5\n","1113/1113 [==============================] - 9s 8ms/step - loss: 11971.0850 - val_loss: 8941.5791\n","Epoch 2/5\n","1113/1113 [==============================] - 10s 9ms/step - loss: 10207.7480 - val_loss: 8678.9102\n","Epoch 3/5\n","1113/1113 [==============================] - 9s 8ms/step - loss: 9719.6348 - val_loss: 8723.6123\n","Epoch 4/5\n","1113/1113 [==============================] - 9s 8ms/step - loss: 9410.3779 - val_loss: 8962.2646\n","Epoch 5/5\n","1113/1113 [==============================] - 9s 8ms/step - loss: 9086.2451 - val_loss: 8947.0283\n","WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","2021-01-31 15:47:38.710512: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SVET52ULOKy1"},"source":["Your model has been saved to your Google Cloud Storage bucket."]},{"cell_type":"code","metadata":{"id":"bpjLdsCcOKy1","outputId":"291e12e7-3b8c-4c1a-f6d2-70de352e3e36"},"source":["!gsutil ls gs://{BUCKET_NAME}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gs://ml-competition-001/latest_model/\n","gs://ml-competition-001/training_job_2021_01_29_170545/\n","gs://ml-competition-001/training_job_2021_01_29_172946/\n","gs://ml-competition-001/training_job_2021_01_31_143525/\n","gs://ml-competition-001/training_job_2021_01_31_144654/\n","gs://ml-competition-001/training_job_2021_01_31_145423/\n","gs://ml-competition-001/training_job_2021_01_31_150103/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hot8GNzaOKy2"},"source":["# AI Platform training"]},{"cell_type":"markdown","metadata":{"id":"U8ktaOw8OKy2"},"source":["Train your model in the cloud.  \n","This can help when you'll need more compute power, run your training for a long periods of time or try several trainings in parallel with hyperparameters search."]},{"cell_type":"markdown","metadata":{"id":"zXFJu_pHOKy2"},"source":["When training through AI Platform you need a few more parameters:\n","* __Region__: the region used by AI Platform for training\n","* __Runtime version__: the AI Platform version you want to use\n","* __Python version__: the Python version used by your package\n","* __Scale tier__: define which compute power will be used (GPU, TPU, number of machines, ...), more details in [this documentation](https://cloud.google.com/ai-platform/training/docs/machine-types)"]},{"cell_type":"markdown","metadata":{"id":"TXZZdq6KOKy2"},"source":["Let's submit a training job with ```gcloud ai-platform jobs submit training``` with a basic configuration (only 1 machine, no GPU, no TPU):"]},{"cell_type":"code","metadata":{"id":"xO20c8xyOKy2","outputId":"bd0a70d9-a57b-46ca-960e-823d2d18d981"},"source":["# Submit the training job\n","! gcloud ai-platform jobs submit training $JOB_NAME \\\n","  --job-dir $JOB_DIR \\\n","  --package-path ./trainer \\\n","  --module-name trainer.task \\\n","  --region $REGION \\\n","  --runtime-version=2.1 \\\n","  --python-version=3.7 \\\n","  --scale-tier basic "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Job [training_job_2021_01_31_154624] submitted successfully.\n","Your job is still active. You may view the status of your job with the command\n","\n","  $ gcloud ai-platform jobs describe training_job_2021_01_31_154624\n","\n","or continue streaming the logs with the command\n","\n","  $ gcloud ai-platform jobs stream-logs training_job_2021_01_31_154624\n","jobId: training_job_2021_01_31_154624\n","state: QUEUED\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a3e2DlqPOKy3"},"source":["The training job is a long running operation.  \n","You can use ```gcloud ai-platform jobs describe``` to get the status of the job:"]},{"cell_type":"code","metadata":{"id":"ioMSA6DzOKy3","outputId":"8749237a-660b-4e20-dde6-ec3258f2bc8d"},"source":["! gcloud ai-platform jobs describe $JOB_NAME"],"execution_count":null,"outputs":[{"output_type":"stream","text":["createTime: '2021-01-31T15:47:53Z'\n","etag: 9waYwEI1I2c=\n","jobId: training_job_2021_01_31_154624\n","state: PREPARING\n","trainingInput:\n","  jobDir: gs://ml-competition-001/training_job_2021_01_31_154624\n","  packageUris:\n","  - gs://ml-competition-001/training_job_2021_01_31_154624/packages/195db6434c3413e086185d9d1aa0a1233a52b66988eedcd85c652d2fcc087a4e/trainer-0.1.tar.gz\n","  pythonModule: trainer.task\n","  pythonVersion: '3.7'\n","  region: europe-west1\n","  runtimeVersion: '2.1'\n","trainingOutput: {}\n","\n","View job in the Cloud Console at:\n","https://console.cloud.google.com/mlengine/jobs/training_job_2021_01_31_154624?project=demoairenault\n","\n","View logs at:\n","https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftraining_job_2021_01_31_154624&project=demoairenault\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B3Nct7d2OKy3"},"source":["Your model has been saved to your Google Cloud Storage bucket."]},{"cell_type":"code","metadata":{"id":"q2myS1CtOKy3","outputId":"19cc9d1c-b456-4c66-a8d3-64f34bd2d93c"},"source":["!gsutil ls gs://{BUCKET_NAME}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gs://ml-competition-001/latest_model/\n","gs://ml-competition-001/training_job_2021_01_29_170545/\n","gs://ml-competition-001/training_job_2021_01_29_172946/\n","gs://ml-competition-001/training_job_2021_01_31_143525/\n","gs://ml-competition-001/training_job_2021_01_31_144654/\n","gs://ml-competition-001/training_job_2021_01_31_145423/\n","gs://ml-competition-001/training_job_2021_01_31_150103/\n","gs://ml-competition-001/training_job_2021_01_31_154624/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vOpjKNj5OKy4"},"source":["# AI Platform deployment\n","\n","Now that you have trained your model, it's time to make it available for serving predictions.  \n","Google [AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs) lets you do just that very easily."]},{"cell_type":"markdown","metadata":{"id":"wgPU4UGJOKy4"},"source":["Let's use ```gsutil ls``` to list your model's file from the Cloud Storage Bucket:"]},{"cell_type":"code","metadata":{"id":"VdvCBO2SOKy4","outputId":"2bcd0723-592b-408f-ece3-43b392e954c0"},"source":["LATEST_MODEL_DIR = f'gs://{BUCKET_NAME}/latest_model/export' \n","!gsutil ls -lh $LATEST_MODEL_DIR"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       0 B  2021-01-29T17:18:29Z  gs://ml-competition-001/latest_model/export/\n","165.64 KiB  2021-01-31T15:47:42Z  gs://ml-competition-001/latest_model/export/saved_model.pb\n","                                 gs://ml-competition-001/latest_model/export/assets/\n","                                 gs://ml-competition-001/latest_model/export/variables/\n","TOTAL: 2 objects, 169614 bytes (165.64 KiB)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bloHk1x0OKy4"},"source":["Set a **name** and a **version** for this model:"]},{"cell_type":"code","metadata":{"id":"IhmM2Vt3OKy5"},"source":["MODEL_NAME = 'kers' # Choose your own model name\n","MODEL_VERSION = 'v1' # Make sure to increase version when deploying a new version of the same model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07VBcpHDOKy5"},"source":["Let's use ```gcloud ai-platform models create```to create a new model:"]},{"cell_type":"code","metadata":{"id":"9dqkllvsOKy5","outputId":"0d4a7911-165b-4118-b1b2-12964618a92b"},"source":["# create a model object at AI Platform first\n","! gcloud ai-platform models create $MODEL_NAME --region $REGION"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using endpoint [https://europe-west1-ml.googleapis.com/]\n","Created ml engine model [projects/demoairenault/models/kers].\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JHfsYVaMOKy5"},"source":["Now that we have the model available in AI Platform, let's create the first version of this model.  \n","We need to point AI Platform to our model in Google Cloud Storage."]},{"cell_type":"code","metadata":{"id":"WGzjp6J6OKy5","outputId":"5290d381-35d9-417a-a9a4-49596cd04d33"},"source":["# Create model version based on that SavedModel directory\n","! gcloud ai-platform versions create $MODEL_VERSION --region $REGION --model $MODEL_NAME \\\n","  --runtime-version 2.1 \\\n","  --python-version 3.7 \\\n","  --framework tensorflow \\\n","  --origin $LATEST_MODEL_DIR \n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using endpoint [https://europe-west1-ml.googleapis.com/]\n","Creating version (this might take a few minutes)......done.                    \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b0a29mCYOKy6"},"source":["# Prediction with AI Platform (from a csv file)\n","At this point we have trained a model and made the model available for serving predictions thanks to AI Platform.  \n","Let's get some predictions from this model."]},{"cell_type":"markdown","metadata":{"id":"W-s8zQe5OKy6"},"source":["## Get the test data\n","Let's grab some fresh data to generate predictions on!"]},{"cell_type":"code","metadata":{"id":"-MI62izWOKy6"},"source":["%%bigquery data_df\n","SELECT \n","       JOBID, VERSION, PERFORMANCE, PRECISION, MPLINK, NTNU, MPLINK_NTNU,\n","       MBS, RUNEND, TIMESTEP, NBNODES, NBELEM1D, NBELEM2D,\n","       NBELEM3D, CLUSTER, NBSERVERS, NBCORE, DATACHECK_TIME,\n","       ELAPSEDTIME\n","FROM\n","  `demoairenault.challenge.training_data`\n","WHERE MOD(JOBID,4) = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiUtQDBUOKy6","outputId":"66e31b52-5d18-44d5-a694-8c403d12e1bf"},"source":["data_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>JOBID</th>\n","      <th>VERSION</th>\n","      <th>PERFORMANCE</th>\n","      <th>PRECISION</th>\n","      <th>MPLINK</th>\n","      <th>NTNU</th>\n","      <th>MPLINK_NTNU</th>\n","      <th>MBS</th>\n","      <th>RUNEND</th>\n","      <th>TIMESTEP</th>\n","      <th>NBNODES</th>\n","      <th>NBELEM1D</th>\n","      <th>NBELEM2D</th>\n","      <th>NBELEM3D</th>\n","      <th>CLUSTER</th>\n","      <th>NBSERVERS</th>\n","      <th>NBCORE</th>\n","      <th>DATACHECK_TIME</th>\n","      <th>ELAPSEDTIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>974258</td>\n","      <td>2018.0.1</td>\n","      <td>PEDESTRIAN</td>\n","      <td>1</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>40.68</td>\n","      <td>0.0005</td>\n","      <td>1647532</td>\n","      <td>3760</td>\n","      <td>1673587</td>\n","      <td>103822</td>\n","      <td>HPC3</td>\n","      <td>1.0</td>\n","      <td>36</td>\n","      <td>74.70</td>\n","      <td>4510</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>974258</td>\n","      <td>2018.0.1</td>\n","      <td>PEDESTRIAN</td>\n","      <td>1</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>40.68</td>\n","      <td>0.0005</td>\n","      <td>1647532</td>\n","      <td>3760</td>\n","      <td>1673587</td>\n","      <td>103822</td>\n","      <td>HPC3</td>\n","      <td>1.0</td>\n","      <td>36</td>\n","      <td>74.70</td>\n","      <td>4510</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>598282</td>\n","      <td>2016.05</td>\n","      <td>UNKNOWN</td>\n","      <td>1</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>30000.00</td>\n","      <td>0.0005</td>\n","      <td>504</td>\n","      <td>0</td>\n","      <td>410</td>\n","      <td>0</td>\n","      <td>HPC1</td>\n","      <td>2.0</td>\n","      <td>48</td>\n","      <td>0.48</td>\n","      <td>7340</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>624046</td>\n","      <td>2016.05</td>\n","      <td>UNKNOWN</td>\n","      <td>1</td>\n","      <td>NO</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>20.00</td>\n","      <td>0.0005</td>\n","      <td>133650</td>\n","      <td>44</td>\n","      <td>127307</td>\n","      <td>0</td>\n","      <td>HPC1</td>\n","      <td>2.0</td>\n","      <td>48</td>\n","      <td>5.86</td>\n","      <td>1870</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>625322</td>\n","      <td>2016.05</td>\n","      <td>UNKNOWN</td>\n","      <td>1</td>\n","      <td>NO</td>\n","      <td>YES</td>\n","      <td>NO</td>\n","      <td>NO</td>\n","      <td>20.00</td>\n","      <td>0.0005</td>\n","      <td>129912</td>\n","      <td>44</td>\n","      <td>128857</td>\n","      <td>0</td>\n","      <td>HPC1</td>\n","      <td>2.0</td>\n","      <td>48</td>\n","      <td>5.76</td>\n","      <td>1930</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    JOBID   VERSION PERFORMANCE  PRECISION MPLINK NTNU MPLINK_NTNU MBS  \\\n","0  974258  2018.0.1  PEDESTRIAN          1     NO   NO          NO  NO   \n","1  974258  2018.0.1  PEDESTRIAN          1     NO   NO          NO  NO   \n","2  598282   2016.05     UNKNOWN          1     NO   NO          NO  NO   \n","3  624046   2016.05     UNKNOWN          1     NO  YES          NO  NO   \n","4  625322   2016.05     UNKNOWN          1     NO  YES          NO  NO   \n","\n","     RUNEND  TIMESTEP  NBNODES  NBELEM1D  NBELEM2D  NBELEM3D CLUSTER  \\\n","0     40.68    0.0005  1647532      3760   1673587    103822    HPC3   \n","1     40.68    0.0005  1647532      3760   1673587    103822    HPC3   \n","2  30000.00    0.0005      504         0       410         0    HPC1   \n","3     20.00    0.0005   133650        44    127307         0    HPC1   \n","4     20.00    0.0005   129912        44    128857         0    HPC1   \n","\n","   NBSERVERS  NBCORE  DATACHECK_TIME  ELAPSEDTIME  \n","0        1.0      36           74.70         4510  \n","1        1.0      36           74.70         4510  \n","2        2.0      48            0.48         7340  \n","3        2.0      48            5.86         1870  \n","4        2.0      48            5.76         1930  "]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"5yqf81laOKy7","outputId":"6a6fca9b-1767-427e-f4d1-3aa68e8a9d03"},"source":["# Need to avoid \"serving skew\"! \n","# Preprocess test data the same way as we did for training\n","CATEGORICAL_TYPES = {'VERSION': pd.api.types.CategoricalDtype(['2018.0.1', '2016.05', '2016.06', '2019.0.2', '2012.7', '2019.0', '2018.0', '2016.01', '2019.0.1', '2019']),\n","                     'PERFORMANCE': pd.api.types.CategoricalDtype(['POLE', 'PEDESTRIAN', 'UNKNOWN', 'ECE', 'FRONT', 'RCAR', 'COCKPIT', 'OVERSLAM', 'REAR', 'SIDE', 'WHEEL']),\n","                    'MPLINK': pd.api.types.CategoricalDtype(['YES', 'NO']),\n","                    'NTNU': pd.api.types.CategoricalDtype(['NO', 'YES']),\n","                    'MPLINK_NTNU': pd.api.types.CategoricalDtype(['NO', 'YES']),\n","                    'MBS': pd.api.types.CategoricalDtype(['NO', 'USED']),\n","                    'CLUSTER':pd.api.types.CategoricalDtype(['HPC3', 'HPC1', 'HPC2'])}\n","                                                              \n","TARGET_COLUMN = 'ELAPSEDTIME'\n","\n","\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 5\n","LEARNING_RATE = 0.001\n","\n","# Read the data from BigQuery\n","# you can read from other sources to pandas DataFrame\n","print(f'First rows for the raw dataset: \\n{data_df.head()}')\n","\n","# Convert integer valued (numeric) columns to floating point\n","numeric_columns = data_df.select_dtypes(['int64']).columns\n","data_df[numeric_columns] = data_df[numeric_columns].astype('float32')\n","\n","# Convert categorical columns to numeric\n","cat_columns = data_df.select_dtypes(['object']).columns\n","data_df[cat_columns] = data_df[cat_columns].astype('category')\n","data_df[cat_columns] = data_df[cat_columns].apply(lambda x: x.astype(\n","        CATEGORICAL_TYPES[x.name]))\n","data_df[cat_columns] = data_df[cat_columns].apply(lambda x: x.cat.codes)\n","print(f'First rows for the transformed dataset: \\n{data_df.head()}')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["First rows for the raw dataset: \n","    JOBID   VERSION PERFORMANCE  PRECISION MPLINK NTNU MPLINK_NTNU MBS  \\\n","0  974258  2018.0.1  PEDESTRIAN          1     NO   NO          NO  NO   \n","1  974258  2018.0.1  PEDESTRIAN          1     NO   NO          NO  NO   \n","2  598282   2016.05     UNKNOWN          1     NO   NO          NO  NO   \n","3  624046   2016.05     UNKNOWN          1     NO  YES          NO  NO   \n","4  625322   2016.05     UNKNOWN          1     NO  YES          NO  NO   \n","\n","     RUNEND  TIMESTEP  NBNODES  NBELEM1D  NBELEM2D  NBELEM3D CLUSTER  \\\n","0     40.68    0.0005  1647532      3760   1673587    103822    HPC3   \n","1     40.68    0.0005  1647532      3760   1673587    103822    HPC3   \n","2  30000.00    0.0005      504         0       410         0    HPC1   \n","3     20.00    0.0005   133650        44    127307         0    HPC1   \n","4     20.00    0.0005   129912        44    128857         0    HPC1   \n","\n","   NBSERVERS  NBCORE  DATACHECK_TIME  ELAPSEDTIME  \n","0        1.0      36           74.70         4510  \n","1        1.0      36           74.70         4510  \n","2        2.0      48            0.48         7340  \n","3        2.0      48            5.86         1870  \n","4        2.0      48            5.76         1930  \n","First rows for the transformed dataset: \n","      JOBID  VERSION  PERFORMANCE  PRECISION  MPLINK  NTNU  MPLINK_NTNU  MBS  \\\n","0  974258.0        0            1        1.0       1     0            0    0   \n","1  974258.0        0            1        1.0       1     0            0    0   \n","2  598282.0        1            2        1.0       1     0            0    0   \n","3  624046.0        1            2        1.0       1     1            0    0   \n","4  625322.0        1            2        1.0       1     1            0    0   \n","\n","     RUNEND  TIMESTEP    NBNODES  NBELEM1D   NBELEM2D  NBELEM3D  CLUSTER  \\\n","0     40.68    0.0005  1647532.0    3760.0  1673587.0  103822.0        0   \n","1     40.68    0.0005  1647532.0    3760.0  1673587.0  103822.0        0   \n","2  30000.00    0.0005      504.0       0.0      410.0       0.0        1   \n","3     20.00    0.0005   133650.0      44.0   127307.0       0.0        1   \n","4     20.00    0.0005   129912.0      44.0   128857.0       0.0        1   \n","\n","   NBSERVERS  NBCORE  DATACHECK_TIME  ELAPSEDTIME  \n","0        1.0    36.0           74.70       4510.0  \n","1        1.0    36.0           74.70       4510.0  \n","2        2.0    48.0            0.48       7340.0  \n","3        2.0    48.0            5.86       1870.0  \n","4        2.0    48.0            5.76       1930.0  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1CmyfDhqOKy7"},"source":["### Prepare prediction input file\n","The `gcloud` command-line tool accepts newline-delimited JSON for online\n","prediction, and this particular Keras model expects a flat list of\n","numbers for each input example.\n","\n","AI Platform requires a different format when you make online prediction requests to the REST API without using the `gcloud` tool. The way you structure\n","your model may also change how you must format data for prediction. Learn more\n","about [formatting data for online\n","prediction](https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_input_data)."]},{"cell_type":"markdown","metadata":{"id":"S_8IwxvROKy7"},"source":["Test first on a few samples:"]},{"cell_type":"code","metadata":{"id":"GwtyPznyOKy7","outputId":"54a9421c-7347-4951-ac96-bca326941541"},"source":["# Export the prediction input to a JSON file in the format accepted by AI Platform\n","import json\n","\n","prediction_dict_sample = test_df.drop('JOBID', axis=1).drop('ELAPSEDTIME',axis=1)[:5].to_dict('records')\n","\n","with open('prediction_input.json', 'w') as json_file:\n","    json.dump({'instances': prediction_dict_sample}, json_file, indent=' ')\n","\n","! cat prediction_input.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\n"," \"instances\": [\n","  {\n","   \"VERSION\": 0,\n","   \"PERFORMANCE\": 1,\n","   \"PRECISION\": 1.0,\n","   \"MPLINK\": 1,\n","   \"NTNU\": 0,\n","   \"MPLINK_NTNU\": 0,\n","   \"MBS\": 0,\n","   \"RUNEND\": 40.68,\n","   \"TIMESTEP\": 0.0005,\n","   \"NBNODES\": 1647532.0,\n","   \"NBELEM1D\": 3760.0,\n","   \"NBELEM2D\": 1673587.0,\n","   \"NBELEM3D\": 103822.0,\n","   \"CLUSTER\": 0,\n","   \"NBSERVERS\": 1.0,\n","   \"NBCORE\": 36.0,\n","   \"DATACHECK_TIME\": 74.7\n","  },\n","  {\n","   \"VERSION\": 0,\n","   \"PERFORMANCE\": 1,\n","   \"PRECISION\": 1.0,\n","   \"MPLINK\": 1,\n","   \"NTNU\": 0,\n","   \"MPLINK_NTNU\": 0,\n","   \"MBS\": 0,\n","   \"RUNEND\": 40.68,\n","   \"TIMESTEP\": 0.0005,\n","   \"NBNODES\": 1647532.0,\n","   \"NBELEM1D\": 3760.0,\n","   \"NBELEM2D\": 1673587.0,\n","   \"NBELEM3D\": 103822.0,\n","   \"CLUSTER\": 0,\n","   \"NBSERVERS\": 1.0,\n","   \"NBCORE\": 36.0,\n","   \"DATACHECK_TIME\": 74.7\n","  },\n","  {\n","   \"VERSION\": 1,\n","   \"PERFORMANCE\": 2,\n","   \"PRECISION\": 1.0,\n","   \"MPLINK\": 1,\n","   \"NTNU\": 0,\n","   \"MPLINK_NTNU\": 0,\n","   \"MBS\": 0,\n","   \"RUNEND\": 30000.0,\n","   \"TIMESTEP\": 0.0005,\n","   \"NBNODES\": 504.0,\n","   \"NBELEM1D\": 0.0,\n","   \"NBELEM2D\": 410.0,\n","   \"NBELEM3D\": 0.0,\n","   \"CLUSTER\": 1,\n","   \"NBSERVERS\": 2.0,\n","   \"NBCORE\": 48.0,\n","   \"DATACHECK_TIME\": 0.48\n","  },\n","  {\n","   \"VERSION\": 1,\n","   \"PERFORMANCE\": 2,\n","   \"PRECISION\": 1.0,\n","   \"MPLINK\": 1,\n","   \"NTNU\": 1,\n","   \"MPLINK_NTNU\": 0,\n","   \"MBS\": 0,\n","   \"RUNEND\": 20.0,\n","   \"TIMESTEP\": 0.0005,\n","   \"NBNODES\": 133650.0,\n","   \"NBELEM1D\": 44.0,\n","   \"NBELEM2D\": 127307.0,\n","   \"NBELEM3D\": 0.0,\n","   \"CLUSTER\": 1,\n","   \"NBSERVERS\": 2.0,\n","   \"NBCORE\": 48.0,\n","   \"DATACHECK_TIME\": 5.86\n","  },\n","  {\n","   \"VERSION\": 1,\n","   \"PERFORMANCE\": 2,\n","   \"PRECISION\": 1.0,\n","   \"MPLINK\": 1,\n","   \"NTNU\": 1,\n","   \"MPLINK_NTNU\": 0,\n","   \"MBS\": 0,\n","   \"RUNEND\": 20.0,\n","   \"TIMESTEP\": 0.0005,\n","   \"NBNODES\": 129912.0,\n","   \"NBELEM1D\": 44.0,\n","   \"NBELEM2D\": 128857.0,\n","   \"NBELEM3D\": 0.0,\n","   \"CLUSTER\": 1,\n","   \"NBSERVERS\": 2.0,\n","   \"NBCORE\": 48.0,\n","   \"DATACHECK_TIME\": 5.76\n","  }\n"," ]\n","}"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EWhez0G6OKy8"},"source":["### Test predictions on few samples"]},{"cell_type":"markdown","metadata":{"id":"taAqvQeNOKy8"},"source":["Use ```gcloud ai-platform predict``` to generate predictions from your model:"]},{"cell_type":"code","metadata":{"id":"nfTZeLa1OKy8","outputId":"54ef4c2f-5f60-4cd5-c7b6-b5db44763607"},"source":["! gcloud ai-platform predict \\\n","  --region $REGION \\\n","  --model $MODEL_NAME \\\n","  --version $MODEL_VERSION \\\n","  --json-request prediction_input.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using endpoint [https://europe-west1-ml.googleapis.com/]\n","[[7710.03711], [7710.03711], [2029.61194], [1901.55], [1439.16016]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kC1zIQ4fOKy8"},"source":["### Online predictions on the whole dataset"]},{"cell_type":"markdown","metadata":{"id":"yB8S7sPmOKy9"},"source":["Let's now get predictions for the whole dataset."]},{"cell_type":"code","metadata":{"id":"FvovuObyOKy9"},"source":["# Helper copied from the AI Platform console\n","import googleapiclient.discovery\n","from google.api_core.client_options import ClientOptions\n","\n","def predict_json(project, model, instances, version=None):\n","    \"\"\"Send json data to a deployed model for prediction.\n","\n","    Args:\n","        project (str): project where the Cloud ML Engine Model is deployed.\n","        model (str): model name.\n","        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n","            your deployed model expects as inputs. Values should be datatypes\n","            convertible to Tensors, or (potentially nested) lists of datatypes\n","            convertible to tensors.\n","        version: str, version of the model to target.\n","    Returns:\n","        Mapping[str: any]: dictionary of prediction results defined by the\n","            model.\n","    \"\"\"\n","    endpoint = 'https://europe-west1-ml.googleapis.com'\n","    client_options = ClientOptions(api_endpoint=endpoint)\n","    service = googleapiclient.discovery.build('ml', 'v1', client_options=client_options)\n","    name = 'projects/{}/models/{}'.format(project, model)\n","\n","    if version is not None:\n","        name += '/versions/{}'.format(version)\n","\n","    response = service.projects().predict(\n","        name=name,\n","        body={'instances': instances}\n","    ).execute()\n","\n","    if 'error' in response:\n","        raise RuntimeError(response['error'])\n","\n","    return response['predictions']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdSzdt9jOKy9"},"source":["We need to provide our Project ID to the online predictions service.  \n","Project ID is a unique identifier for the Google Cloud environment you are currently using.  \n","Let's use ```gcloud config get-value project``` to get this property from gcloud:"]},{"cell_type":"code","metadata":{"id":"fziJ_ByeOKy9"},"source":["PROJECT_ID = !gcloud config get-value project"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tv_jBHDaOKy9"},"source":["PROJECT_ID = PROJECT_ID.get_nlstr()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tErkOQP5OKy9"},"source":["from functools import partial"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmwjegyNOKy-","outputId":"b7aacd98-f48f-4466-c468-23efe4e6e319"},"source":["!echo $MODEL_NAME"],"execution_count":null,"outputs":[{"output_type":"stream","text":["kers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bai2B7nyOKy-"},"source":["get_predictions = partial(\n","    predict_json,\n","    project=PROJECT_ID, \n","    model='kers', \n","    version='v1'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pc-xEV1kOKy-"},"source":["BATCH_SIZE = 1024"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zm44SpgROKy-","outputId":"03cf4fc8-4a03-453c-f34a-593e2cea044a"},"source":["num_batches = len(test_df)//BATCH_SIZE; num_batches"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"id":"5hUCgzaROKy_","outputId":"19417a91-8a07-4e89-86d8-616ddda3cb71"},"source":["test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VERSION</th>\n","      <th>PERFORMANCE</th>\n","      <th>PRECISION</th>\n","      <th>MPLINK</th>\n","      <th>NTNU</th>\n","      <th>MPLINK_NTNU</th>\n","      <th>MBS</th>\n","      <th>RUNEND</th>\n","      <th>TIMESTEP</th>\n","      <th>NBNODES</th>\n","      <th>NBELEM1D</th>\n","      <th>NBELEM2D</th>\n","      <th>NBELEM3D</th>\n","      <th>CLUSTER</th>\n","      <th>NBSERVERS</th>\n","      <th>NBCORE</th>\n","      <th>DATACHECK_TIME</th>\n","      <th>ELAPSEDTIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40.68</td>\n","      <td>0.0005</td>\n","      <td>1647532.0</td>\n","      <td>3760.0</td>\n","      <td>1673587.0</td>\n","      <td>103822.0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>36.0</td>\n","      <td>74.70</td>\n","      <td>4510.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40.68</td>\n","      <td>0.0005</td>\n","      <td>1647532.0</td>\n","      <td>3760.0</td>\n","      <td>1673587.0</td>\n","      <td>103822.0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>36.0</td>\n","      <td>74.70</td>\n","      <td>4510.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30000.00</td>\n","      <td>0.0005</td>\n","      <td>504.0</td>\n","      <td>0.0</td>\n","      <td>410.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>48.0</td>\n","      <td>0.48</td>\n","      <td>7340.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20.00</td>\n","      <td>0.0005</td>\n","      <td>133650.0</td>\n","      <td>44.0</td>\n","      <td>127307.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>48.0</td>\n","      <td>5.86</td>\n","      <td>1870.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20.00</td>\n","      <td>0.0005</td>\n","      <td>129912.0</td>\n","      <td>44.0</td>\n","      <td>128857.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>48.0</td>\n","      <td>5.76</td>\n","      <td>1930.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>44599</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>160.01</td>\n","      <td>0.0005</td>\n","      <td>7819462.0</td>\n","      <td>24134.0</td>\n","      <td>7760306.0</td>\n","      <td>837887.0</td>\n","      <td>0</td>\n","      <td>6.0</td>\n","      <td>216.0</td>\n","      <td>851.00</td>\n","      <td>39800.0</td>\n","    </tr>\n","    <tr>\n","      <th>44600</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.01</td>\n","      <td>0.0005</td>\n","      <td>8107110.0</td>\n","      <td>31068.0</td>\n","      <td>7255714.0</td>\n","      <td>2287615.0</td>\n","      <td>0</td>\n","      <td>6.0</td>\n","      <td>216.0</td>\n","      <td>782.00</td>\n","      <td>29800.0</td>\n","    </tr>\n","    <tr>\n","      <th>44601</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.01</td>\n","      <td>0.0005</td>\n","      <td>8107110.0</td>\n","      <td>31068.0</td>\n","      <td>7255714.0</td>\n","      <td>2287615.0</td>\n","      <td>0</td>\n","      <td>6.0</td>\n","      <td>216.0</td>\n","      <td>782.00</td>\n","      <td>30100.0</td>\n","    </tr>\n","    <tr>\n","      <th>44602</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.01</td>\n","      <td>0.0005</td>\n","      <td>8107110.0</td>\n","      <td>31068.0</td>\n","      <td>7255714.0</td>\n","      <td>2287615.0</td>\n","      <td>0</td>\n","      <td>6.0</td>\n","      <td>216.0</td>\n","      <td>782.00</td>\n","      <td>29800.0</td>\n","    </tr>\n","    <tr>\n","      <th>44603</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.01</td>\n","      <td>0.0005</td>\n","      <td>8107110.0</td>\n","      <td>31068.0</td>\n","      <td>7255714.0</td>\n","      <td>2287615.0</td>\n","      <td>0</td>\n","      <td>6.0</td>\n","      <td>216.0</td>\n","      <td>782.00</td>\n","      <td>30100.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>44604 rows × 18 columns</p>\n","</div>"],"text/plain":["       VERSION  PERFORMANCE  PRECISION  MPLINK  NTNU  MPLINK_NTNU  MBS  \\\n","0            0            1        1.0       1     0            0    0   \n","1            0            1        1.0       1     0            0    0   \n","2            1            2        1.0       1     0            0    0   \n","3            1            2        1.0       1     1            0    0   \n","4            1            2        1.0       1     1            0    0   \n","...        ...          ...        ...     ...   ...          ...  ...   \n","44599        0            4        1.0       1     0            1    1   \n","44600        0            4        1.0       1     0            1    0   \n","44601        0            4        1.0       1     0            1    0   \n","44602        0            4        1.0       1     0            1    0   \n","44603        0            4        1.0       1     0            1    0   \n","\n","         RUNEND  TIMESTEP    NBNODES  NBELEM1D   NBELEM2D   NBELEM3D  CLUSTER  \\\n","0         40.68    0.0005  1647532.0    3760.0  1673587.0   103822.0        0   \n","1         40.68    0.0005  1647532.0    3760.0  1673587.0   103822.0        0   \n","2      30000.00    0.0005      504.0       0.0      410.0        0.0        1   \n","3         20.00    0.0005   133650.0      44.0   127307.0        0.0        1   \n","4         20.00    0.0005   129912.0      44.0   128857.0        0.0        1   \n","...         ...       ...        ...       ...        ...        ...      ...   \n","44599    160.01    0.0005  7819462.0   24134.0  7760306.0   837887.0        0   \n","44600    120.01    0.0005  8107110.0   31068.0  7255714.0  2287615.0        0   \n","44601    120.01    0.0005  8107110.0   31068.0  7255714.0  2287615.0        0   \n","44602    120.01    0.0005  8107110.0   31068.0  7255714.0  2287615.0        0   \n","44603    120.01    0.0005  8107110.0   31068.0  7255714.0  2287615.0        0   \n","\n","       NBSERVERS  NBCORE  DATACHECK_TIME  ELAPSEDTIME  \n","0            1.0    36.0           74.70       4510.0  \n","1            1.0    36.0           74.70       4510.0  \n","2            2.0    48.0            0.48       7340.0  \n","3            2.0    48.0            5.86       1870.0  \n","4            2.0    48.0            5.76       1930.0  \n","...          ...     ...             ...          ...  \n","44599        6.0   216.0          851.00      39800.0  \n","44600        6.0   216.0          782.00      29800.0  \n","44601        6.0   216.0          782.00      30100.0  \n","44602        6.0   216.0          782.00      29800.0  \n","44603        6.0   216.0          782.00      30100.0  \n","\n","[44604 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"Pkj-CPsYOKy_","outputId":"e9c2cd7c-0cdc-42a7-85ed-50e0c08a6f16"},"source":["prediction_scores = []\n","df = test_df.drop('ELAPSEDTIME',axis=1)\n","\n","for i in tqdm(range(num_batches+1), total=num_batches, position=0):\n","    batch_df = df.iloc[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n","    pred = get_predictions(instances=batch_df.to_dict('records'))\n","    #print(pred)\n","    #pred = [p['dense_1'][0] for p in pred]\n","    prediction_scores.extend(pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["44it [00:08,  5.12it/s]                        \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3btxaJHEOKy_","outputId":"4944f891-194c-485d-9d47-74851fd0cbfa"},"source":["prediction_scores[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[7710.03711], [7710.03711], [2029.61194], [1901.55], [1439.16016]]"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"xQelrSBbOKzB"},"source":["# Clean up"]},{"cell_type":"markdown","metadata":{"id":"JK4546IvOKzB"},"source":["Delete all versions and all models:"]},{"cell_type":"code","metadata":{"id":"nu-Oe6SpOKzB"},"source":["import time\n","import googleapiclient.discovery\n","\n","service = googleapiclient.discovery.build('ml', 'v1')\n","\n","project = !gcloud config get-value project\n","project = project.get_nlstr()\n","\n","def get_models(project):\n","    response = service.projects().models().list(\n","        parent = 'projects/{}'.format(project)\n","    ).execute()\n","    \n","    return response[\"models\"]\n","\n","def get_versions(model):\n","    response = service.projects().models().versions().list(\n","        parent=model\n","    ).execute()\n","    \n","    return response[\"versions\"]\n","\n","def delete_version(version):\n","    print(\"Deleting version: \", version[\"name\"])\n","    \n","    response = service.projects().models().versions().delete(\n","        name=version[\"name\"]\n","    ).execute()\n","    \n","    if \"error\" in response:\n","        print(error)\n","    \n","    return response[\"name\"]\n","\n","def delete_model(model):\n","    print(\"Deleting model: \", model[\"name\"])\n","    \n","    response = service.projects().models().delete(\n","        name=model[\"name\"]\n","    ).execute()\n","    \n","    if \"error\" in response:\n","        print(error)\n","\n","def is_version_deleted(operation):\n","    print(\"Checking status for operation: \", operation)\n","    \n","    response = service.projects().operations().get(\n","        name=operation\n","    ).execute()\n","    \n","    print(response)\n","    if \"done\" in response:\n","        return True\n","    else:\n","        return False\n","\n","models = get_models(project)\n","\n","default_version_deletions = []\n","for model in models:\n","    print('Model: ', model[\"name\"])\n","    versions = get_versions(model[\"name\"])\n","    deletions_in_progress = []\n","    for version in versions:\n","        # Delete non default versions\n","        if \"isDefault\" not in version:\n","            versions.remove(version)\n","            deletions_in_progress.append(delete_version(version))\n","    while len(deletions_in_progress) > 0:\n","        # Try again in 5s\n","        print(\"Waiting 5s\")\n","        time.sleep(5)\n","        for deletion_in_progress in deletions_in_progress:\n","            if is_version_deleted(deletion_in_progress):\n","                print(\"Deletion completed: \", deletion_in_progress)\n","                deletions_in_progress.remove(deletion_in_progress)\n","    # When all default versions are deleted, remove the default version\n","    default_version_deletions.append(delete_version(versions[0]))\n","while len(default_version_deletions) > 0:\n","    # Try again in 5s\n","    print(\"Waiting 5s\")\n","    time.sleep(5)\n","    for default_version_deletion in default_version_deletions:\n","        if is_version_deleted(default_version_deletion):\n","            print(\"Deletion completed: \", default_version_deletion)\n","            default_version_deletions.remove(default_version_deletion)\n","# All versions deleted, now delete the model\n","for model in models:\n","    delete_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5OZw2ZwKOKzB"},"source":["Delete the bucket:"]},{"cell_type":"code","metadata":{"id":"h2SpN5O_OKzB"},"source":["# Delete your bucket\n","!gsutil rm -r gs://{BUCKET_NAME}"],"execution_count":null,"outputs":[]}]}